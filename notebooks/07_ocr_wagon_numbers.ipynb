{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d31e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c0718ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"[INFO] Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68946d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path: Path) -> np.ndarray:\n",
    "    img = cv2.imread(str(path))\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to read image: {path}\")\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c31e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text_regions(img: np.ndarray) -> List[np.ndarray]:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    _, thresh = cv2.threshold(\n",
    "        blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15,5))\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "    contours, _ = cv2.findContours(\n",
    "        dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    regions = []\n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if w > 40 and h > 15:\n",
    "            regions.append(img[y:y+h, x:x+w])\n",
    "\n",
    "    return regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes=36):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            128 * 8,\n",
    "            128,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.permute(0,3,1,2).contiguous()\n",
    "        x = x.view(b, w, c*h)\n",
    "        x,_ = self.rnn(x)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "OCR_MODEL_PATH = Path(\"../outputs/models/ocr/best_model.pth\")\n",
    "\n",
    "ocr_model = CRNN().to(DEVICE)\n",
    "ocr_model.eval()\n",
    "\n",
    "if OCR_MODEL_PATH.exists():\n",
    "    state = torch.load(OCR_MODEL_PATH, map_location=DEVICE)\n",
    "    ocr_model.load_state_dict(state[\"model_state\"])\n",
    "    print(\"✅ OCR model loaded\")\n",
    "else:\n",
    "    print(\"⚠️ No pretrained OCR model found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "def decode_prediction(logits: torch.Tensor) -> str:\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "    preds = preds.squeeze(0).cpu().numpy()\n",
    "\n",
    "    prev = -1\n",
    "    text = \"\"\n",
    "    for p in preds:\n",
    "        if p != prev and p < len(ALPHABET):\n",
    "            text += ALPHABET[p]\n",
    "        prev = p\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386fe4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def ocr_on_image(img: np.ndarray) -> List[str]:\n",
    "    regions = detect_text_regions(img)\n",
    "    results = []\n",
    "\n",
    "    for r in regions:\n",
    "        gray = cv2.cvtColor(r, cv2.COLOR_RGB2GRAY)\n",
    "        gray = cv2.resize(gray, (128,32))\n",
    "        t = torch.from_numpy(gray).float() / 255.0\n",
    "        t = t.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        logits = ocr_model(t)\n",
    "        text = decode_prediction(logits)\n",
    "        results.append(text)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b004ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_ocr(raw_img: np.ndarray, enhanced_img: np.ndarray):\n",
    "    raw_text = ocr_on_image(raw_img)\n",
    "    enh_text = ocr_on_image(enhanced_img)\n",
    "\n",
    "    print(\"Raw OCR:\", raw_text)\n",
    "    print(\"Enhanced OCR:\", enh_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0413a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ocr(img_path: Path):\n",
    "    img = read_image(img_path)\n",
    "    texts = ocr_on_image(img)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"OCR Output: {texts}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
