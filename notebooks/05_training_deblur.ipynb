{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b7acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n",
      "[INFO] Directory structure initialized\n",
      "‚úÖ GoPro dataset ready.\n",
      "‚úÖ RealBlur dataset ready.\n",
      "‚úÖ LOL dataset ready.\n",
      "‚úÖ ICDAR 2015 dataset ready.\n",
      "\n",
      "‚ùó RailSem19 NOT found.\n",
      "Download from: https://www.railsense.org/datasets/railsem19\n",
      "Extract into: C:\\Users\\Swayam\\OneDrive\\Desktop\\Adani - RailVision\\data\\datasets\\RailSem19\n"
     ]
    }
   ],
   "source": [
    "%run ../notebooks/01_data_and_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9064bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a736e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"[INFO] Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec3b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# DATASET PATHS\n",
    "# =====================\n",
    "GOPRO_DIR = Path(\"../data/datasets/GoPro\")\n",
    "\n",
    "TRAIN_BLUR = GOPRO_DIR / \"train/blur\"\n",
    "TRAIN_SHARP = GOPRO_DIR / \"train/sharp\"\n",
    "\n",
    "VAL_BLUR = GOPRO_DIR / \"test/blur\"\n",
    "VAL_SHARP = GOPRO_DIR / \"test/sharp\"\n",
    "\n",
    "# =====================\n",
    "# OUTPUT PATHS\n",
    "# =====================\n",
    "MODEL_SAVE_DIR = Path(\"../outputs/models/deblur\")\n",
    "MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =====================\n",
    "# TRAINING PARAMS\n",
    "# =====================\n",
    "BATCH_SIZE = 4          # small batch\n",
    "NUM_EPOCHS = 200        # long training\n",
    "LR = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a34cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    img = cv2.imread(str(path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img.astype(np.float32) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "833765c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(img):\n",
    "    return torch.from_numpy(img).permute(2, 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89152600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GoProDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        root_dir = GoPro/train OR GoPro/test\n",
    "        \"\"\"\n",
    "        self.pairs = []\n",
    "\n",
    "        for seq in sorted(root_dir.iterdir()):\n",
    "            blur_dir = seq / \"blur\"\n",
    "            sharp_dir = seq / \"sharp\"\n",
    "\n",
    "            if not blur_dir.exists():\n",
    "                continue\n",
    "\n",
    "            blur_imgs = sorted(\n",
    "                list(blur_dir.glob(\"*.png\")) + list(blur_dir.glob(\"*.jpg\"))\n",
    "            )\n",
    "\n",
    "            for b in blur_imgs:\n",
    "                s = sharp_dir / b.name\n",
    "                if s.exists():\n",
    "                    self.pairs.append((b, s))\n",
    "\n",
    "        if len(self.pairs) == 0:\n",
    "            raise RuntimeError(f\"No image pairs found in {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        blur_path, sharp_path = self.pairs[idx]\n",
    "\n",
    "        blur = read_image(blur_path)\n",
    "        sharp = read_image(sharp_path)\n",
    "\n",
    "        # üî• IMPORTANT: resize (huge memory saver)\n",
    "        blur = cv2.resize(blur, (256, 256))\n",
    "        sharp = cv2.resize(sharp, (256, 256))\n",
    "\n",
    "        blur = to_tensor(blur)\n",
    "        sharp = to_tensor(sharp)\n",
    "\n",
    "        return blur, sharp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc92669",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GoProDataset(GOPRO_DIR / \"train\")\n",
    "val_dataset   = GoProDataset(GOPRO_DIR / \"test\")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,   # ‚úÖ FIX\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "817b4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv2(self.relu(self.conv1(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "883e1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeblurGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.head = nn.Conv2d(3, 64, 7, padding=3)\n",
    "        self.body = nn.Sequential(*[ResBlock(64) for _ in range(9)])\n",
    "        self.tail = nn.Conv2d(64, 3, 7, padding=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.head(x))\n",
    "        x = self.body(x)\n",
    "        return torch.sigmoid(self.tail(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b3ac9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swayam\\AppData\\Local\\Temp\\ipykernel_30112\\3753310028.py:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE.type == \"cuda\"))\n"
     ]
    }
   ],
   "source": [
    "model = DeblurGenerator().to(DEVICE)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "# üî• IMPORTANT: Mixed Precision + Memory Safety\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE.type == \"cuda\"))\n",
    "\n",
    "# Optional but recommended\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6dfd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    psnr_vals, ssim_vals = [], []\n",
    "\n",
    "    for blur, sharp in loader:\n",
    "        blur = blur.to(DEVICE)\n",
    "        sharp = sharp.to(DEVICE)\n",
    "\n",
    "        out = model(blur)\n",
    "\n",
    "        out_np = out[0].permute(1,2,0).cpu().numpy()\n",
    "        sharp_np = sharp[0].permute(1,2,0).cpu().numpy()\n",
    "\n",
    "        psnr_vals.append(psnr(sharp_np, out_np))\n",
    "        ssim_vals.append(\n",
    "            ssim(\n",
    "                sharp_np,\n",
    "                out_np,\n",
    "                channel_axis=2,\n",
    "                data_range=1.0   # üî• FIX\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    return np.mean(psnr_vals), np.mean(ssim_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "615bc10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/526 [00:00<?, ?it/s]C:\\Users\\Swayam\\AppData\\Local\\Temp\\ipykernel_30112\\970465203.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 0:  41%|‚ñà‚ñà‚ñà‚ñà      | 215/526 [01:20<01:55,  2.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      6\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blur, sharp \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      9\u001b[0m     blur \u001b[38;5;241m=\u001b[39m blur\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     10\u001b[0m     sharp \u001b[38;5;241m=\u001b[39m sharp\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32mc:\\Users\\Swayam\\OneDrive\\Desktop\\Adani - RailVision\\gpuenv\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Swayam\\OneDrive\\Desktop\\Adani - RailVision\\gpuenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Swayam\\OneDrive\\Desktop\\Adani - RailVision\\gpuenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Swayam\\OneDrive\\Desktop\\Adani - RailVision\\gpuenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Swayam\\OneDrive\\Desktop\\Adani - RailVision\\gpuenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[7], line 36\u001b[0m, in \u001b[0;36mGoProDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     33\u001b[0m blur_path, sharp_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpairs[idx]\n\u001b[0;32m     35\u001b[0m blur \u001b[38;5;241m=\u001b[39m read_image(blur_path)\n\u001b[1;32m---> 36\u001b[0m sharp \u001b[38;5;241m=\u001b[39m \u001b[43mread_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43msharp_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# üî• IMPORTANT: resize (huge memory saver)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m blur \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(blur, (\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_psnr = -1\n",
    "train_losses, val_psnrs = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for blur, sharp in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        blur = blur.to(DEVICE)\n",
    "        sharp = sharp.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out = model(blur)\n",
    "            loss = criterion(out, sharp)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    val_psnr, val_ssim = evaluate(model, val_loader)\n",
    "    val_psnrs.append(val_psnr)\n",
    "\n",
    "    # ---- Saving ----\n",
    "    save_epoch_model(\n",
    "        model, optimizer, epoch, epoch_loss, MODEL_SAVE_DIR,\n",
    "        metrics={\"psnr\": val_psnr, \"ssim\": val_ssim}\n",
    "    )\n",
    "\n",
    "    save_checkpoint(\n",
    "        model, optimizer, scheduler, epoch, best_psnr, MODEL_SAVE_DIR\n",
    "    )\n",
    "\n",
    "    if val_psnr > best_psnr:\n",
    "        best_psnr = val_psnr\n",
    "        save_best_model(model, optimizer, epoch, best_psnr, MODEL_SAVE_DIR)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(\n",
    "        f\"[Epoch {epoch}] \"\n",
    "        f\"Loss={epoch_loss:.4f} | \"\n",
    "        f\"PSNR={val_psnr:.2f} | \"\n",
    "        f\"SSIM={val_ssim:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558dce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses)\n",
    "plt.title(\"Training Loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(val_psnrs)\n",
    "plt.title(\"Validation PSNR\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8fe7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed00c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
