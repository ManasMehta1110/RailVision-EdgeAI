{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17619b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =====================\n",
    "# CONFIG\n",
    "# =====================\n",
    "VIDEO_PATH = Path(\"../data/raw_videos/WhatsApp Video 2026-01-08 at 15.55.48.mp4\")\n",
    "\n",
    "LOWLIGHT_MODEL_PATH = Path(\"../outputs/models/low_light/best_model_lowlight.pth\")\n",
    "DEBLUR_MODEL_PATH   = Path(\"../outputs/models/deblur/best_model_deblur.pth\")\n",
    "\n",
    "OUTPUT_PATH = Path(\"FINAL_lowlight_then_deblur.mp4\")\n",
    "\n",
    "FRAME_SKIP = 10       # üî• SAFE SPEEDUP\n",
    "DEFAULT_FPS = 50\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"[INFO] Device:\", DEVICE)\n",
    "\n",
    "# =====================\n",
    "# MODELS (MATCH TRAINING)\n",
    "# =====================\n",
    "\n",
    "class ZeroDCE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(32, 24, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.relu(self.conv1(x))\n",
    "        x2 = self.relu(self.conv2(x1))\n",
    "        x3 = self.relu(self.conv3(x2))\n",
    "        x4 = self.relu(self.conv4(x3))\n",
    "        x5 = self.relu(self.conv5(x4))\n",
    "        x6 = self.relu(self.conv6(x5))\n",
    "        return torch.tanh(self.conv7(x6))\n",
    "\n",
    "def apply_curves(img, curves, n=8):\n",
    "    out = img\n",
    "    for i in range(n):\n",
    "        r = curves[:, i*3:(i+1)*3]\n",
    "        out = out + r * (out**2 - out)\n",
    "    return torch.clamp(out, 0, 1)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(c, c, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(c, c, 3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv2(self.relu(self.conv1(x)))\n",
    "\n",
    "class DeblurGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.head = nn.Conv2d(3, 64, 7, padding=3)\n",
    "        self.body = nn.Sequential(*[ResBlock(64) for _ in range(9)])\n",
    "        self.tail = nn.Conv2d(64, 3, 7, padding=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.head(x))\n",
    "        x = self.body(x)\n",
    "        return torch.sigmoid(self.tail(x))\n",
    "\n",
    "# =====================\n",
    "# LOAD MODELS (SAFE)\n",
    "# =====================\n",
    "lowlight = ZeroDCE().to(DEVICE)\n",
    "low_ckpt = torch.load(LOWLIGHT_MODEL_PATH, map_location=DEVICE, weights_only=True)\n",
    "lowlight.load_state_dict(low_ckpt[\"model_state\"])\n",
    "lowlight.eval()\n",
    "\n",
    "\n",
    "deblur = DeblurGenerator().to(DEVICE)\n",
    "deblur_ckpt = torch.load(DEBLUR_MODEL_PATH, map_location=DEVICE, weights_only=True)\n",
    "deblur.load_state_dict(deblur_ckpt[\"model_state\"])\n",
    "deblur.eval()\n",
    "\n",
    "\n",
    "print(\"[INFO] Models loaded successfully\")\n",
    "\n",
    "# =====================\n",
    "# VIDEO SETUP\n",
    "# =====================\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "assert cap.isOpened(), \"‚ùå Cannot open video\"\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fps = fps if fps > 1 else DEFAULT_FPS\n",
    "out_fps = fps / FRAME_SKIP\n",
    "\n",
    "ret, frame = cap.read()\n",
    "assert ret, \"‚ùå No frames\"\n",
    "\n",
    "h, w = frame.shape[:2]\n",
    "\n",
    "writer = cv2.VideoWriter(\n",
    "    str(OUTPUT_PATH),\n",
    "    cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "    out_fps,\n",
    "    (w * 2, h)\n",
    ")\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# =====================\n",
    "# FINAL PIPELINE\n",
    "# =====================\n",
    "frame_id = 0\n",
    "processed = 0\n",
    "\n",
    "print(\"[INFO] Starting FINAL pipeline inference...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in tqdm(range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_id % FRAME_SKIP != 0:\n",
    "            frame_id += 1\n",
    "            continue\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        inp = torch.from_numpy(rgb / 255.0)\\\n",
    "                    .permute(2,0,1)\\\n",
    "                    .unsqueeze(0)\\\n",
    "                    .float()\\\n",
    "                    .to(DEVICE)\n",
    "\n",
    "        # ---- LOW LIGHT ----\n",
    "        curves = lowlight(inp)\n",
    "        enhanced = apply_curves(inp, curves)\n",
    "\n",
    "        # ---- DEBLUR ----\n",
    "        restored = deblur(enhanced)\n",
    "\n",
    "        out = restored[0].permute(1,2,0).cpu().numpy()\n",
    "        out = np.clip(out * 255, 0, 255).astype(np.uint8)\n",
    "        out_bgr = cv2.cvtColor(out, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        combined = np.hstack([frame, out_bgr])\n",
    "        writer.write(combined)\n",
    "\n",
    "        processed += 1\n",
    "        frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "print(\"[DONE]\")\n",
    "print(f\"[INFO] Frames processed: {processed}\")\n",
    "print(f\"[INFO] Output saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b649e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =====================\n",
    "# CONFIG\n",
    "# =====================\n",
    "VIDEO_PATH = Path(\"../data/raw_videos/high_speed_axis_55kmph_night.mp4\")\n",
    "DEBLUR_MODEL_PATH = Path(\"../outputs/models/deblur/best_model_deblur.pth\")\n",
    "OUTPUT_PATH = Path(\"deblur_only_output.mp4\")\n",
    "\n",
    "FRAME_SKIP = 2.5        # speed-up (process every 5th frame)\n",
    "DEFAULT_FPS = 50\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"[INFO] Device:\", DEVICE)\n",
    "\n",
    "# =====================\n",
    "# MODEL (MATCHES TRAINING)\n",
    "# =====================\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(c, c, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(c, c, 3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv2(self.relu(self.conv1(x)))\n",
    "\n",
    "class DeblurGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.head = nn.Conv2d(3, 64, 7, padding=3)\n",
    "        self.body = nn.Sequential(*[ResBlock(64) for _ in range(9)])\n",
    "        self.tail = nn.Conv2d(64, 3, 7, padding=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.head(x))\n",
    "        x = self.body(x)\n",
    "        return torch.sigmoid(self.tail(x))\n",
    "\n",
    "# =====================\n",
    "# LOAD MODEL (CORRECT)\n",
    "# =====================\n",
    "model = DeblurGenerator().to(DEVICE)\n",
    "ckpt = torch.load(DEBLUR_MODEL_PATH, map_location=DEVICE, weights_only=True)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval()\n",
    "\n",
    "print(\"[INFO] Deblur model loaded successfully\")\n",
    "\n",
    "# =====================\n",
    "# VIDEO SETUP\n",
    "# =====================\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "assert cap.isOpened(), \"‚ùå Cannot open video\"\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fps = fps if fps > 1 else DEFAULT_FPS\n",
    "\n",
    "ret, frame = cap.read()\n",
    "assert ret, \"‚ùå No frames in video\"\n",
    "\n",
    "h, w = frame.shape[:2]\n",
    "\n",
    "writer = cv2.VideoWriter(\n",
    "    str(OUTPUT_PATH),\n",
    "    cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "    fps // FRAME_SKIP,\n",
    "    (w * 2, h)\n",
    ")\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# =====================\n",
    "# INFERENCE LOOP\n",
    "# =====================\n",
    "frame_id = 0\n",
    "processed = 0\n",
    "\n",
    "print(\"[INFO] Starting DEBLUR-ONLY inference...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in tqdm(range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_id % FRAME_SKIP != 0:\n",
    "            frame_id += 1\n",
    "            continue\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        inp = torch.from_numpy(rgb / 255.0)\\\n",
    "                    .permute(2,0,1)\\\n",
    "                    .unsqueeze(0)\\\n",
    "                    .float()\\\n",
    "                    .to(DEVICE)\n",
    "\n",
    "        out = model(inp)[0].permute(1,2,0).cpu().numpy()\n",
    "        out = (out * 255).astype(np.uint8)\n",
    "        out_bgr = cv2.cvtColor(out, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        combined = np.hstack([frame, out_bgr])\n",
    "        writer.write(combined)\n",
    "\n",
    "        processed += 1\n",
    "        frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "print(\"[DONE]\")\n",
    "print(f\"[INFO] Frames processed: {processed}\")\n",
    "print(f\"[INFO] Output saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d735313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "\n",
    "# ==========================\n",
    "# CONFIG\n",
    "# ==========================\n",
    "VIDEO_PATH = Path(\"../data/raw_videos/high_speed_axis_55kmph_night.mp4\")\n",
    "OUTPUT_PATH = Path(\"final_stable_pipeline.mp4\")\n",
    "\n",
    "DEBLUR_ONNX = \"../onnx_models/deblur.onnx\"\n",
    "OCR_ONNX    = \"../onnx_models/ocr.onnx\"\n",
    "\n",
    "FRAME_SKIP   = 5\n",
    "OCR_EVERY_N  = 20\n",
    "DEFAULT_FPS  = 50\n",
    "\n",
    "EDGE_VAR_THRESH = 80.0\n",
    "OCR_CONF_THRESH = 0.65\n",
    "TEMPORAL_WINDOW = 5\n",
    "\n",
    "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "PROVIDERS = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "\n",
    "# ==========================\n",
    "# LOAD MODELS\n",
    "# ==========================\n",
    "deb_sess = ort.InferenceSession(DEBLUR_ONNX, providers=PROVIDERS)\n",
    "ocr_sess = ort.InferenceSession(OCR_ONNX, providers=PROVIDERS)\n",
    "\n",
    "deb_in = deb_sess.get_inputs()[0].name\n",
    "ocr_in = ocr_sess.get_inputs()[0].name\n",
    "\n",
    "# ==========================\n",
    "# VIDEO SETUP\n",
    "# ==========================\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "assert cap.isOpened(), \"‚ùå Cannot open video\"\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fps = fps if fps > 1 else DEFAULT_FPS\n",
    "fps /= FRAME_SKIP\n",
    "\n",
    "ret, first = cap.read()\n",
    "assert ret, \"‚ùå Empty video\"\n",
    "\n",
    "H, W = first.shape[:2]\n",
    "\n",
    "writer = cv2.VideoWriter(\n",
    "    str(OUTPUT_PATH),\n",
    "    cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "    fps,\n",
    "    (W * 2, H)\n",
    ")\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# ==========================\n",
    "# HELPERS\n",
    "# ==========================\n",
    "def softmax(x, axis=-1):\n",
    "    x = x - np.max(x, axis=axis, keepdims=True)\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e, axis=axis, keepdims=True)\n",
    "\n",
    "def decode_ctc(logits):\n",
    "    probs = softmax(logits, axis=-1)\n",
    "    preds = probs.argmax(axis=-1)[0]\n",
    "\n",
    "    prev = -1\n",
    "    text, confs = \"\", []\n",
    "\n",
    "    for t, p in enumerate(preds):\n",
    "        if p != prev and p != 0:\n",
    "            text += ALPHABET[p - 1]\n",
    "            confs.append(probs[0, t, p])\n",
    "        prev = p\n",
    "\n",
    "    if not confs:\n",
    "        return \"\", 0.0\n",
    "\n",
    "    return text, float(np.mean(confs))\n",
    "\n",
    "def get_text_roi(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    return (\n",
    "        int(w * 0.25),\n",
    "        int(h * 0.45),\n",
    "        int(w * 0.75),\n",
    "        int(h * 0.65),\n",
    "    )\n",
    "\n",
    "def has_text_like_content(gray):\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var() > EDGE_VAR_THRESH\n",
    "\n",
    "# ==========================\n",
    "# TEMPORAL OCR BUFFER\n",
    "# ==========================\n",
    "buffer = deque(maxlen=TEMPORAL_WINDOW)\n",
    "final_text = \"\"\n",
    "\n",
    "# ==========================\n",
    "# MAIN LOOP\n",
    "# ==========================\n",
    "frame_id = 0\n",
    "processed = 0\n",
    "\n",
    "print(\"[INFO] Starting STABLE pipeline...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_id % FRAME_SKIP != 0:\n",
    "        frame_id += 1\n",
    "        continue\n",
    "\n",
    "    original = frame.copy()\n",
    "\n",
    "    # -------------------------\n",
    "    # DEBLUR (ALWAYS ON)\n",
    "    # -------------------------\n",
    "    inp = frame.astype(np.float32) / 255.0\n",
    "    inp = inp.transpose(2, 0, 1)[None]\n",
    "\n",
    "    deblurred = deb_sess.run(None, {deb_in: inp})[0][0]\n",
    "    deblurred = (deblurred.transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "\n",
    "    # -------------------------\n",
    "    # OCR (RAW, NOT DEBLURRED)\n",
    "    # -------------------------\n",
    "    if processed % OCR_EVERY_N == 0:\n",
    "        x1, y1, x2, y2 = get_text_roi(original)\n",
    "        roi = original[y1:y2, x1:x2]\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if has_text_like_content(gray):\n",
    "            gray = cv2.resize(gray, (128, 32))\n",
    "            ocr_inp = (gray.astype(np.float32) / 255.0)[None, None]\n",
    "\n",
    "            logits = ocr_sess.run(None, {ocr_in: ocr_inp})[0]\n",
    "            text, conf = decode_ctc(logits)\n",
    "\n",
    "            if conf >= OCR_CONF_THRESH:\n",
    "                buffer.append(text)\n",
    "                if len(buffer) == TEMPORAL_WINDOW and len(set(buffer)) == 1:\n",
    "                    final_text = buffer[0]\n",
    "                    print(f\"[OCR ‚úì] {final_text}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # VISUALIZATION\n",
    "    # -------------------------\n",
    "    vis = deblurred.copy()\n",
    "    if final_text:\n",
    "        cv2.putText(\n",
    "            vis, final_text,\n",
    "            (30, 50),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1.3, (0, 255, 0), 3\n",
    "        )\n",
    "\n",
    "    combined = np.hstack([original, vis])\n",
    "    writer.write(combined)\n",
    "\n",
    "    processed += 1\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "print(\"‚úÖ DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================\n",
    "# CONFIG\n",
    "# ==========================\n",
    "VIDEO_PATH = Path(\"../data/raw_videos/high_speed_axis_55kmph_night.mp4\")\n",
    "OUTPUT_PATH = Path(\"patch_deblur_output.mp4\")\n",
    "\n",
    "DEBLUR_ONNX = \"../onnx_models/deblur.onnx\"\n",
    "OCR_ONNX    = \"../onnx_models/ocr.onnx\"\n",
    "\n",
    "FRAME_SKIP   = 5\n",
    "OCR_EVERY_N  = 20\n",
    "DEFAULT_FPS  = 50\n",
    "\n",
    "# Patch parameters\n",
    "TILE_SIZE = 256\n",
    "OVERLAP   = 32\n",
    "STEP      = 224\n",
    "\n",
    "# OCR parameters\n",
    "EDGE_VAR_THRESH = 80.0\n",
    "OCR_CONF_THRESH = 0.65\n",
    "TEMPORAL_WINDOW = 5\n",
    "\n",
    "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "PROVIDERS = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "\n",
    "# ==========================\n",
    "# LOAD MODELS\n",
    "# ==========================\n",
    "deb_sess = ort.InferenceSession(DEBLUR_ONNX, providers=PROVIDERS)\n",
    "ocr_sess = ort.InferenceSession(OCR_ONNX, providers=PROVIDERS)\n",
    "\n",
    "deb_in = deb_sess.get_inputs()[0].name\n",
    "ocr_in = ocr_sess.get_inputs()[0].name\n",
    "\n",
    "# ==========================\n",
    "# VIDEO SETUP\n",
    "# ==========================\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "assert cap.isOpened(), \"‚ùå Cannot open video\"\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "total_to_process = total_frames // FRAME_SKIP\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fps = fps if fps > 1 else DEFAULT_FPS\n",
    "fps /= FRAME_SKIP\n",
    "\n",
    "ret, first = cap.read()\n",
    "assert ret, \"‚ùå Empty video\"\n",
    "\n",
    "H, W = first.shape[:2]\n",
    "\n",
    "writer = cv2.VideoWriter(\n",
    "    str(OUTPUT_PATH),\n",
    "    cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "    fps,\n",
    "    (W * 2, H)\n",
    ")\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# ==========================\n",
    "# HELPERS\n",
    "# ==========================\n",
    "def softmax(x, axis=-1):\n",
    "    x = x - np.max(x, axis=axis, keepdims=True)\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e, axis=axis, keepdims=True)\n",
    "\n",
    "def decode_ctc(logits):\n",
    "    probs = softmax(logits, axis=-1)\n",
    "    preds = probs.argmax(axis=-1)[0]\n",
    "\n",
    "    prev = -1\n",
    "    text, confs = \"\", []\n",
    "\n",
    "    for t, p in enumerate(preds):\n",
    "        if p != prev and p != 0:\n",
    "            text += ALPHABET[p - 1]\n",
    "            confs.append(probs[0, t, p])\n",
    "        prev = p\n",
    "\n",
    "    if not confs:\n",
    "        return \"\", 0.0\n",
    "\n",
    "    return text, float(np.mean(confs))\n",
    "\n",
    "def has_text_like_content(gray):\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var() > EDGE_VAR_THRESH\n",
    "\n",
    "def get_text_roi(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    return (\n",
    "        int(w * 0.25),\n",
    "        int(h * 0.45),\n",
    "        int(w * 0.75),\n",
    "        int(h * 0.65),\n",
    "    )\n",
    "\n",
    "# ==========================\n",
    "# PATCH-BASED DEBLUR\n",
    "# ==========================\n",
    "def patch_deblur(frame):\n",
    "    h, w, _ = frame.shape\n",
    "    acc = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    weight = np.zeros((h, w, 1), dtype=np.float32)\n",
    "\n",
    "    for y in range(0, h - TILE_SIZE + 1, STEP):\n",
    "        for x in range(0, w - TILE_SIZE + 1, STEP):\n",
    "            tile = frame[y:y+TILE_SIZE, x:x+TILE_SIZE]\n",
    "\n",
    "            inp = (tile.astype(np.float32) / 255.0)\n",
    "            inp = inp.transpose(2, 0, 1)[None]\n",
    "\n",
    "            out = deb_sess.run(None, {deb_in: inp})[0][0]\n",
    "            out = out.transpose(1, 2, 0)\n",
    "\n",
    "            acc[y:y+TILE_SIZE, x:x+TILE_SIZE] += out\n",
    "            weight[y:y+TILE_SIZE, x:x+TILE_SIZE] += 1.0\n",
    "\n",
    "    deblurred = acc / np.maximum(weight, 1e-6)\n",
    "    return (np.clip(deblurred, 0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "# ==========================\n",
    "# OCR TEMPORAL BUFFER\n",
    "# ==========================\n",
    "buffer = deque(maxlen=TEMPORAL_WINDOW)\n",
    "final_text = \"\"\n",
    "\n",
    "# ==========================\n",
    "# MAIN LOOP (WITH tqdm)\n",
    "# ==========================\n",
    "frame_id = 0\n",
    "processed = 0\n",
    "\n",
    "pbar = tqdm(total=total_to_process, desc=\"Processing frames\", unit=\"frame\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_id % FRAME_SKIP != 0:\n",
    "        frame_id += 1\n",
    "        continue\n",
    "\n",
    "    original = frame.copy()\n",
    "\n",
    "    # -------------------------\n",
    "    # PATCH-BASED DEBLUR\n",
    "    # -------------------------\n",
    "    deblurred = patch_deblur(frame)\n",
    "\n",
    "    # -------------------------\n",
    "    # OCR (RAW FRAME ONLY)\n",
    "    # -------------------------\n",
    "    if processed % OCR_EVERY_N == 0:\n",
    "        x1, y1, x2, y2 = get_text_roi(original)\n",
    "        roi = original[y1:y2, x1:x2]\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if has_text_like_content(gray):\n",
    "            gray = cv2.resize(gray, (128, 32))\n",
    "            ocr_inp = (gray.astype(np.float32) / 255.0)[None, None]\n",
    "\n",
    "            logits = ocr_sess.run(None, {ocr_in: ocr_inp})[0]\n",
    "            text, conf = decode_ctc(logits)\n",
    "\n",
    "            if conf >= OCR_CONF_THRESH:\n",
    "                buffer.append(text)\n",
    "                if len(buffer) == TEMPORAL_WINDOW and len(set(buffer)) == 1:\n",
    "                    final_text = buffer[0]\n",
    "                    tqdm.write(f\"[OCR ‚úì] {final_text}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # VISUALIZATION\n",
    "    # -------------------------\n",
    "    vis = deblurred.copy()\n",
    "    if final_text:\n",
    "        cv2.putText(\n",
    "            vis,\n",
    "            final_text,\n",
    "            (30, 50),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1.3,\n",
    "            (0, 255, 0),\n",
    "            3\n",
    "        )\n",
    "\n",
    "    combined = np.hstack([original, vis])\n",
    "    writer.write(combined)\n",
    "\n",
    "    processed += 1\n",
    "    frame_id += 1\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "print(\"‚úÖ DONE\")\n",
    "print(f\"üìΩ Frames processed: {processed}\")\n",
    "print(f\"üé¨ Output saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d707ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================\n",
    "# CONFIG\n",
    "# ==========================\n",
    "VIDEO_PATH = Path(\"../data/raw_videos/high_speed_axis_55kmph_night.mp4\")\n",
    "OUTPUT_PATH = Path(\"patch_deblur_output.mp4\")\n",
    "\n",
    "DEBLUR_ONNX = \"../onnx_models/deblur.onnx\"\n",
    "OCR_ONNX    = \"../onnx_models/ocr.onnx\"\n",
    "\n",
    "FRAME_SKIP   = 5\n",
    "OCR_EVERY_N  = 20\n",
    "DEFAULT_FPS  = 50\n",
    "\n",
    "# Patch parameters\n",
    "TILE_SIZE = 256\n",
    "OVERLAP   = 32\n",
    "STEP      = 224\n",
    "\n",
    "# OCR parameters\n",
    "EDGE_VAR_THRESH = 80.0\n",
    "OCR_CONF_THRESH = 0.65\n",
    "TEMPORAL_WINDOW = 5\n",
    "\n",
    "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "PROVIDERS = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "\n",
    "# ==========================\n",
    "# LOAD MODELS\n",
    "# ==========================\n",
    "deb_sess = ort.InferenceSession(DEBLUR_ONNX, providers=PROVIDERS)\n",
    "ocr_sess = ort.InferenceSession(OCR_ONNX, providers=PROVIDERS)\n",
    "\n",
    "deb_in = deb_sess.get_inputs()[0].name\n",
    "ocr_in = ocr_sess.get_inputs()[0].name\n",
    "\n",
    "# ==========================\n",
    "# VIDEO SETUP\n",
    "# ==========================\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "assert cap.isOpened(), \"‚ùå Cannot open video\"\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "total_to_process = total_frames // FRAME_SKIP\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fps = fps if fps > 1 else DEFAULT_FPS\n",
    "fps /= FRAME_SKIP\n",
    "\n",
    "ret, first = cap.read()\n",
    "assert ret, \"‚ùå Empty video\"\n",
    "\n",
    "H, W = first.shape[:2]\n",
    "\n",
    "writer = cv2.VideoWriter(\n",
    "    str(OUTPUT_PATH),\n",
    "    cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "    fps,\n",
    "    (W * 2, H)\n",
    ")\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# ==========================\n",
    "# HELPERS\n",
    "# ==========================\n",
    "def softmax(x, axis=-1):\n",
    "    x = x - np.max(x, axis=axis, keepdims=True)\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e, axis=axis, keepdims=True)\n",
    "\n",
    "def decode_ctc(logits):\n",
    "    probs = softmax(logits, axis=-1)\n",
    "    preds = probs.argmax(axis=-1)[0]\n",
    "\n",
    "    prev = -1\n",
    "    text, confs = \"\", []\n",
    "\n",
    "    for t, p in enumerate(preds):\n",
    "        if p != prev and p != 0:\n",
    "            text += ALPHABET[p - 1]\n",
    "            confs.append(probs[0, t, p])\n",
    "        prev = p\n",
    "\n",
    "    if not confs:\n",
    "        return \"\", 0.0\n",
    "\n",
    "    return text, float(np.mean(confs))\n",
    "\n",
    "def has_text_like_content(gray):\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var() > EDGE_VAR_THRESH\n",
    "\n",
    "def get_text_roi(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    return (\n",
    "        int(w * 0.25),\n",
    "        int(h * 0.45),\n",
    "        int(w * 0.75),\n",
    "        int(h * 0.65),\n",
    "    )\n",
    "\n",
    "# ==========================\n",
    "# PATCH-BASED DEBLUR\n",
    "# ==========================\n",
    "def patch_deblur(frame):\n",
    "    h, w, _ = frame.shape\n",
    "    acc = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    weight = np.zeros((h, w, 1), dtype=np.float32)\n",
    "\n",
    "    for y in range(0, h - TILE_SIZE + 1, STEP):\n",
    "        for x in range(0, w - TILE_SIZE + 1, STEP):\n",
    "            tile = frame[y:y+TILE_SIZE, x:x+TILE_SIZE]\n",
    "\n",
    "            inp = (tile.astype(np.float32) / 255.0)\n",
    "            inp = inp.transpose(2, 0, 1)[None]\n",
    "\n",
    "            out = deb_sess.run(None, {deb_in: inp})[0][0]\n",
    "            out = out.transpose(1, 2, 0)\n",
    "\n",
    "            acc[y:y+TILE_SIZE, x:x+TILE_SIZE] += out\n",
    "            weight[y:y+TILE_SIZE, x:x+TILE_SIZE] += 1.0\n",
    "\n",
    "    deblurred = acc / np.maximum(weight, 1e-6)\n",
    "    return (np.clip(deblurred, 0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "# ==========================\n",
    "# OCR TEMPORAL BUFFER\n",
    "# ==========================\n",
    "buffer = deque(maxlen=TEMPORAL_WINDOW)\n",
    "final_text = \"\"\n",
    "\n",
    "# ==========================\n",
    "# MAIN LOOP (WITH tqdm)\n",
    "# ==========================\n",
    "frame_id = 0\n",
    "processed = 0\n",
    "\n",
    "pbar = tqdm(total=total_to_process, desc=\"Processing frames\", unit=\"frame\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_id % FRAME_SKIP != 0:\n",
    "        frame_id += 1\n",
    "        continue\n",
    "\n",
    "    original = frame.copy()\n",
    "\n",
    "    # -------------------------\n",
    "    # PATCH-BASED DEBLUR\n",
    "    # -------------------------\n",
    "    deblurred = patch_deblur(frame)\n",
    "\n",
    "    # -------------------------\n",
    "    # OCR (RAW FRAME ONLY)\n",
    "    # -------------------------\n",
    "    if processed % OCR_EVERY_N == 0:\n",
    "        x1, y1, x2, y2 = get_text_roi(original)\n",
    "        roi = original[y1:y2, x1:x2]\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if has_text_like_content(gray):\n",
    "            gray = cv2.resize(gray, (128, 32))\n",
    "            ocr_inp = (gray.astype(np.float32) / 255.0)[None, None]\n",
    "\n",
    "            logits = ocr_sess.run(None, {ocr_in: ocr_inp})[0]\n",
    "            text, conf = decode_ctc(logits)\n",
    "\n",
    "            if conf >= OCR_CONF_THRESH:\n",
    "                buffer.append(text)\n",
    "                if len(buffer) == TEMPORAL_WINDOW and len(set(buffer)) == 1:\n",
    "                    final_text = buffer[0]\n",
    "                    tqdm.write(f\"[OCR ‚úì] {final_text}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # VISUALIZATION\n",
    "    # -------------------------\n",
    "    vis = deblurred.copy()\n",
    "    if final_text:\n",
    "        cv2.putText(\n",
    "            vis,\n",
    "            final_text,\n",
    "            (30, 50),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1.3,\n",
    "            (0, 255, 0),\n",
    "            3\n",
    "        )\n",
    "\n",
    "    combined = np.hstack([original, vis])\n",
    "    writer.write(combined)\n",
    "\n",
    "    processed += 1\n",
    "    frame_id += 1\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "print(\"‚úÖ DONE\")\n",
    "print(f\"üìΩ Frames processed: {processed}\")\n",
    "print(f\"üé¨ Output saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17094e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, deque\n",
    "from pathlib import Path\n",
    "import onnxruntime as ort\n",
    "import pytesseract\n",
    "import os\n",
    "\n",
    "# =====================================================\n",
    "# PATHS (ROBUST)\n",
    "# =====================================================\n",
    "VIDEO_PATH = Path(\"../data/raw_videos/high_speed_axis_55kmph_night.mp4\")\n",
    "\n",
    "LOWLIGHT_ONNX = Path(\"../onnx_models/lowlight.onnx\")\n",
    "DEBLUR_ONNX   = Path(\"../onnx_models/deblur.onnx\")\n",
    "OCR_ONNX      = Path(\"../onnx_models/ocr.onnx\")\n",
    "\n",
    "# ---- sanity checks ----\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"Video resolved to:\", VIDEO_PATH.resolve())\n",
    "assert VIDEO_PATH.exists(), f\"‚ùå Video not found: {VIDEO_PATH.resolve()}\"\n",
    "assert LOWLIGHT_ONNX.exists(), \"‚ùå Missing lowlight ONNX\"\n",
    "assert DEBLUR_ONNX.exists(), \"‚ùå Missing deblur ONNX\"\n",
    "assert OCR_ONNX.exists(), \"‚ùå Missing OCR ONNX\"\n",
    "\n",
    "# =====================================================\n",
    "# GAP DETECTION (ROBUST)\n",
    "# =====================================================\n",
    "MIN_GAP_DROP = 0.08          # normalized (night-safe)\n",
    "COOLDOWN_FRAMES = 10\n",
    "\n",
    "# =====================================================\n",
    "# STRICT ENHANCEMENT THRESHOLDS\n",
    "# =====================================================\n",
    "LOWLIGHT_MEAN_THRESH = 40\n",
    "LOWLIGHT_STD_THRESH  = 25\n",
    "BLUR_LAPLACIAN_THRESH = 35.0\n",
    "\n",
    "# =====================================================\n",
    "# OCR CONFIG\n",
    "# =====================================================\n",
    "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "FRAME_SKIP_OCR = 3\n",
    "TEMPORAL_WINDOW = 5\n",
    "\n",
    "EDGE_DENSITY_THRESH = 0.02\n",
    "TESS_CONF_THRESH = 70\n",
    "\n",
    "TESS_CONFIG = (\n",
    "    \"--oem 1 \"\n",
    "    \"--psm 7 \"\n",
    "    \"-c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    ")\n",
    "\n",
    "# ROI (tune ONCE if needed)\n",
    "ROI_X1_FRAC = 0.25\n",
    "ROI_X2_FRAC = 0.75\n",
    "ROI_Y1_FRAC = 0.45\n",
    "ROI_Y2_FRAC = 0.65\n",
    "\n",
    "# =====================================================\n",
    "# PATCH DEBLUR PARAMS\n",
    "# =====================================================\n",
    "TILE_SIZE = 256\n",
    "OVERLAP = 32\n",
    "STEP = TILE_SIZE - OVERLAP\n",
    "\n",
    "# =====================================================\n",
    "# LOAD MODELS\n",
    "# =====================================================\n",
    "providers = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "\n",
    "low_sess = ort.InferenceSession(str(LOWLIGHT_ONNX), providers=providers)\n",
    "deb_sess = ort.InferenceSession(str(DEBLUR_ONNX), providers=providers)\n",
    "ocr_sess = ort.InferenceSession(str(OCR_ONNX), providers=providers)\n",
    "\n",
    "low_in = low_sess.get_inputs()[0].name\n",
    "deb_in = deb_sess.get_inputs()[0].name\n",
    "ocr_in = ocr_sess.get_inputs()[0].name\n",
    "\n",
    "# =====================================================\n",
    "# HELPERS\n",
    "# =====================================================\n",
    "def softmax(x, axis=-1):\n",
    "    x = x - np.max(x, axis=axis, keepdims=True)\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e, axis=axis, keepdims=True)\n",
    "\n",
    "def decode_ctc(logits):\n",
    "    probs = softmax(logits, axis=-1)\n",
    "    preds = probs.argmax(axis=-1)[0]\n",
    "    prev = -1\n",
    "    text = \"\"\n",
    "    for p in preds:\n",
    "        if p != prev and 1 <= p <= len(ALPHABET):\n",
    "            text += ALPHABET[p - 1]\n",
    "        prev = p\n",
    "    return text\n",
    "\n",
    "def is_text_like(gray):\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    return (edges.mean() / 255.0) > EDGE_DENSITY_THRESH\n",
    "\n",
    "def preprocess_for_tesseract(roi):\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    bin_img = cv2.adaptiveThreshold(\n",
    "        gray, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        31, 5\n",
    "    )\n",
    "    return cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, np.ones((2,2), np.uint8))\n",
    "\n",
    "def tesseract_ocr(bin_img):\n",
    "    data = pytesseract.image_to_data(\n",
    "        bin_img,\n",
    "        config=TESS_CONFIG,\n",
    "        output_type=pytesseract.Output.DICT\n",
    "    )\n",
    "    texts, confs = [], []\n",
    "    for txt, conf in zip(data[\"text\"], data[\"conf\"]):\n",
    "        if txt.strip() and int(conf) > 0:\n",
    "            texts.append(txt)\n",
    "            confs.append(int(conf))\n",
    "    if not texts:\n",
    "        return \"\", 0.0\n",
    "    return \"\".join(texts), float(np.mean(confs))\n",
    "\n",
    "def is_low_light(gray):\n",
    "    return gray.mean() < LOWLIGHT_MEAN_THRESH and gray.std() < LOWLIGHT_STD_THRESH\n",
    "\n",
    "def is_blurry(gray):\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var() < BLUR_LAPLACIAN_THRESH\n",
    "\n",
    "def apply_zero_dce(img, curves):\n",
    "    out = img\n",
    "    for i in range(8):\n",
    "        r = curves[:, i*3:(i+1)*3]\n",
    "        out = out + r * (out*out - out)\n",
    "    return np.clip(out, 0, 1)\n",
    "\n",
    "def patch_deblur(frame):\n",
    "    h, w, _ = frame.shape\n",
    "    tiles, coords = [], []\n",
    "    for y in range(0, h - TILE_SIZE + 1, STEP):\n",
    "        for x in range(0, w - TILE_SIZE + 1, STEP):\n",
    "            tiles.append(frame[y:y+TILE_SIZE, x:x+TILE_SIZE])\n",
    "            coords.append((y, x))\n",
    "    if not tiles:\n",
    "        return frame\n",
    "\n",
    "    batch = np.stack([\n",
    "        t.astype(np.float32).transpose(2,0,1) / 255.0\n",
    "        for t in tiles\n",
    "    ])\n",
    "    out = deb_sess.run(None, {deb_in: batch})[0].transpose(0,2,3,1)\n",
    "\n",
    "    acc = np.zeros((h,w,3), np.float32)\n",
    "    weight = np.zeros((h,w,1), np.float32)\n",
    "    for (y,x), tile in zip(coords, out):\n",
    "        acc[y:y+TILE_SIZE, x:x+TILE_SIZE] += tile\n",
    "        weight[y:y+TILE_SIZE, x:x+TILE_SIZE] += 1\n",
    "\n",
    "    return (np.clip(acc / np.maximum(weight,1e-6),0,1)*255).astype(np.uint8)\n",
    "\n",
    "# =====================================================\n",
    "# MAIN LOOP (SAFE)\n",
    "# =====================================================\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "assert cap.isOpened(), \"‚ùå OpenCV cannot open the video\"\n",
    "\n",
    "prev_profile = None\n",
    "cooldown = 0\n",
    "wagon_index = 1\n",
    "\n",
    "ocr_buffer = deque(maxlen=TEMPORAL_WINDOW)\n",
    "wagon_texts = defaultdict(list)\n",
    "\n",
    "print(\"üöÜ START ‚Üí Wagon #1\")\n",
    "\n",
    "pbar = tqdm(desc=\"Processing video\", unit=\"frame\")\n",
    "frame_id = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_id += 1\n",
    "    pbar.update(1)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    profile = gray.mean(axis=0)\n",
    "\n",
    "    # ---------- GAP DETECTION ----------\n",
    "    if prev_profile is not None:\n",
    "        diff = np.abs(prev_profile - profile)\n",
    "        drop = diff.mean() / (profile.mean() + 1e-6)\n",
    "        if drop > MIN_GAP_DROP and cooldown == 0:\n",
    "            wagon_index += 1\n",
    "            cooldown = COOLDOWN_FRAMES\n",
    "            print(f\"\\nüîπ GAP ‚Üí Wagon #{wagon_index}\")\n",
    "\n",
    "    prev_profile = profile\n",
    "    cooldown = max(0, cooldown - 1)\n",
    "\n",
    "    # ---------- STRICT VISUAL ENHANCEMENT ----------\n",
    "    vis = frame.copy()\n",
    "    if is_low_light(gray):\n",
    "        rgb = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
    "        inp = (rgb/255.0).transpose(2,0,1)[None]\n",
    "        curves = low_sess.run(None, {low_in: inp})[0]\n",
    "        vis = (apply_zero_dce(inp, curves)[0].transpose(1,2,0)*255).astype(np.uint8)\n",
    "\n",
    "    if is_blurry(gray):\n",
    "        vis = patch_deblur(vis)\n",
    "\n",
    "    # ---------- OCR (RAW ONLY) ----------\n",
    "    if frame_id % FRAME_SKIP_OCR == 0:\n",
    "        H,W = frame.shape[:2]\n",
    "        roi = frame[\n",
    "            int(H*ROI_Y1_FRAC):int(H*ROI_Y2_FRAC),\n",
    "            int(W*ROI_X1_FRAC):int(W*ROI_X2_FRAC)\n",
    "        ]\n",
    "        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if is_text_like(gray_roi):\n",
    "            bin_img = preprocess_for_tesseract(roi)\n",
    "            text, conf = tesseract_ocr(bin_img)\n",
    "\n",
    "            if conf >= TESS_CONF_THRESH:\n",
    "                ocr_buffer.append(text)\n",
    "            else:\n",
    "                resized = cv2.resize(gray_roi,(128,32))\n",
    "                inp = (resized/255.0).astype(np.float32)[None,None]\n",
    "                logits = ocr_sess.run(None,{ocr_in:inp})[0]\n",
    "                ocr_buffer.append(decode_ctc(logits))\n",
    "\n",
    "            if len(ocr_buffer)==TEMPORAL_WINDOW and len(set(ocr_buffer))==1:\n",
    "                wagon_texts[wagon_index].append(ocr_buffer[0])\n",
    "                print(f\"[OCR] Wagon #{wagon_index}: {ocr_buffer[0]}\")\n",
    "\n",
    "cap.release()\n",
    "pbar.close()\n",
    "\n",
    "# =====================================================\n",
    "# RESULTS\n",
    "# =====================================================\n",
    "print(\"\\n==============================\")\n",
    "print(f\"‚úÖ TOTAL WAGONS: {wagon_index}\")\n",
    "print(\"==============================\")\n",
    "\n",
    "for i in range(1, wagon_index+1):\n",
    "    texts = wagon_texts[i]\n",
    "    if texts:\n",
    "        print(f\"Wagon #{i}: {max(set(texts), key=texts.count)}\")\n",
    "    else:\n",
    "        print(f\"Wagon #{i}: <NO TEXT>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f014a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, deque\n",
    "import onnxruntime as ort\n",
    "import pytesseract\n",
    "\n",
    "# =====================================================\n",
    "# PATHS\n",
    "# =====================================================\n",
    "VIDEO_PATH = \"raw_videos/high_speed_axis_55kmph_night.mp4\"\n",
    "\n",
    "LOWLIGHT_ONNX = \"../onnx_models/lowlight.onnx\"\n",
    "DEBLUR_ONNX   = \"../onnx_models/deblur.onnx\"\n",
    "OCR_ONNX      = \"../onnx_models/ocr.onnx\"\n",
    "\n",
    "# =====================================================\n",
    "# GAP DETECTION (ROBUST)\n",
    "# =====================================================\n",
    "MIN_GAP_DROP = 0.08          # normalized drop (night-safe)\n",
    "COOLDOWN_FRAMES = 10\n",
    "\n",
    "# =====================================================\n",
    "# STRICT ENHANCEMENT THRESHOLDS\n",
    "# =====================================================\n",
    "LOWLIGHT_MEAN_THRESH = 40\n",
    "LOWLIGHT_STD_THRESH  = 25\n",
    "BLUR_LAPLACIAN_THRESH = 35.0\n",
    "\n",
    "# =====================================================\n",
    "# OCR CONFIG\n",
    "# =====================================================\n",
    "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "FRAME_SKIP_OCR = 3\n",
    "TEMPORAL_WINDOW = 5\n",
    "\n",
    "EDGE_DENSITY_THRESH = 0.02\n",
    "TESS_CONF_THRESH = 70\n",
    "\n",
    "TESS_CONFIG = (\n",
    "    \"--oem 1 \"\n",
    "    \"--psm 7 \"\n",
    "    \"-c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    ")\n",
    "\n",
    "# ROI (tune ONCE if needed)\n",
    "ROI_X1_FRAC = 0.25\n",
    "ROI_X2_FRAC = 0.75\n",
    "ROI_Y1_FRAC = 0.45\n",
    "ROI_Y2_FRAC = 0.65\n",
    "\n",
    "# =====================================================\n",
    "# PATCH DEBLUR PARAMS\n",
    "# =====================================================\n",
    "TILE_SIZE = 256\n",
    "OVERLAP = 32\n",
    "STEP = TILE_SIZE - OVERLAP\n",
    "\n",
    "# =====================================================\n",
    "# LOAD MODELS\n",
    "# =====================================================\n",
    "providers = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "\n",
    "low_sess = ort.InferenceSession(LOWLIGHT_ONNX, providers=providers)\n",
    "deb_sess = ort.InferenceSession(DEBLUR_ONNX, providers=providers)\n",
    "ocr_sess = ort.InferenceSession(OCR_ONNX, providers=providers)\n",
    "\n",
    "low_in = low_sess.get_inputs()[0].name\n",
    "deb_in = deb_sess.get_inputs()[0].name\n",
    "ocr_in = ocr_sess.get_inputs()[0].name\n",
    "\n",
    "# =====================================================\n",
    "# HELPERS\n",
    "# =====================================================\n",
    "def softmax(x, axis=-1):\n",
    "    x = x - np.max(x, axis=axis, keepdims=True)\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e, axis=axis, keepdims=True)\n",
    "\n",
    "def decode_ctc(logits):\n",
    "    probs = softmax(logits, axis=-1)\n",
    "    preds = probs.argmax(axis=-1)[0]\n",
    "    prev = -1\n",
    "    text = \"\"\n",
    "    for p in preds:\n",
    "        if p != prev and 1 <= p <= len(ALPHABET):\n",
    "            text += ALPHABET[p - 1]\n",
    "        prev = p\n",
    "    return text\n",
    "\n",
    "def is_text_like(gray):\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    return (edges.mean() / 255.0) > EDGE_DENSITY_THRESH\n",
    "\n",
    "def preprocess_for_tesseract(roi):\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    bin_img = cv2.adaptiveThreshold(\n",
    "        gray, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        31, 5\n",
    "    )\n",
    "    return cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, np.ones((2,2), np.uint8))\n",
    "\n",
    "def tesseract_ocr(bin_img):\n",
    "    data = pytesseract.image_to_data(\n",
    "        bin_img,\n",
    "        config=TESS_CONFIG,\n",
    "        output_type=pytesseract.Output.DICT\n",
    "    )\n",
    "    texts, confs = [], []\n",
    "    for txt, conf in zip(data[\"text\"], data[\"conf\"]):\n",
    "        if txt.strip() and int(conf) > 0:\n",
    "            texts.append(txt)\n",
    "            confs.append(int(conf))\n",
    "    if not texts:\n",
    "        return \"\", 0.0\n",
    "    return \"\".join(texts), float(np.mean(confs))\n",
    "\n",
    "def is_low_light(gray):\n",
    "    return gray.mean() < LOWLIGHT_MEAN_THRESH and gray.std() < LOWLIGHT_STD_THRESH\n",
    "\n",
    "def is_blurry(gray):\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var() < BLUR_LAPLACIAN_THRESH\n",
    "\n",
    "def apply_zero_dce(img, curves):\n",
    "    out = img\n",
    "    for i in range(8):\n",
    "        r = curves[:, i*3:(i+1)*3]\n",
    "        out = out + r * (out*out - out)\n",
    "    return np.clip(out, 0, 1)\n",
    "\n",
    "def patch_deblur(frame):\n",
    "    h, w, _ = frame.shape\n",
    "    tiles, coords = [], []\n",
    "    for y in range(0, h - TILE_SIZE + 1, STEP):\n",
    "        for x in range(0, w - TILE_SIZE + 1, STEP):\n",
    "            tiles.append(frame[y:y+TILE_SIZE, x:x+TILE_SIZE])\n",
    "            coords.append((y, x))\n",
    "    if not tiles:\n",
    "        return frame\n",
    "    batch = np.stack([\n",
    "        t.astype(np.float32).transpose(2,0,1) / 255.0\n",
    "        for t in tiles\n",
    "    ])\n",
    "    out = deb_sess.run(None, {deb_in: batch})[0].transpose(0,2,3,1)\n",
    "    acc = np.zeros((h,w,3), np.float32)\n",
    "    weight = np.zeros((h,w,1), np.float32)\n",
    "    for (y,x), tile in zip(coords, out):\n",
    "        acc[y:y+TILE_SIZE, x:x+TILE_SIZE] += tile\n",
    "        weight[y:y+TILE_SIZE, x:x+TILE_SIZE] += 1\n",
    "    return (np.clip(acc / np.maximum(weight,1e-6),0,1)*255).astype(np.uint8)\n",
    "\n",
    "# =====================================================\n",
    "# MAIN LOOP (FIXED)\n",
    "# =====================================================\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "assert cap.isOpened(), f\"‚ùå Cannot open video: {VIDEO_PATH}\"\n",
    "\n",
    "prev_profile = None\n",
    "cooldown = 0\n",
    "wagon_index = 0\n",
    "\n",
    "ocr_buffer = deque(maxlen=TEMPORAL_WINDOW)\n",
    "wagon_texts = defaultdict(list)\n",
    "\n",
    "print(\"üöÜ START ‚Üí Wagon #1\")\n",
    "\n",
    "pbar = tqdm(desc=\"Processing video\", unit=\"frame\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    profile = gray.mean(axis=0)\n",
    "\n",
    "    # ---------- GAP DETECTION ----------\n",
    "    if prev_profile is not None:\n",
    "        diff = np.abs(prev_profile - profile)\n",
    "        drop = diff.mean() / (profile.mean() + 1e-6)\n",
    "        if drop > MIN_GAP_DROP and cooldown == 0:\n",
    "            wagon_index += 1\n",
    "            cooldown = COOLDOWN_FRAMES\n",
    "            print(f\"\\nüîπ GAP ‚Üí Wagon #{wagon_index}\")\n",
    "\n",
    "    prev_profile = profile\n",
    "    cooldown = max(0, cooldown - 1)\n",
    "\n",
    "    # ---------- STRICT VISUAL ENHANCEMENT ----------\n",
    "    vis = frame.copy()\n",
    "    if is_low_light(gray):\n",
    "        rgb = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
    "        inp = (rgb/255.0).transpose(2,0,1)[None]\n",
    "        curves = low_sess.run(None, {low_in: inp})[0]\n",
    "        vis = (apply_zero_dce(inp, curves)[0].transpose(1,2,0)*255).astype(np.uint8)\n",
    "\n",
    "    if is_blurry(gray):\n",
    "        vis = patch_deblur(vis)\n",
    "\n",
    "    # ---------- OCR (RAW ONLY) ----------\n",
    "    if frame_id = pbar.n\n",
    "    if wagon_index >= 1 and frame_id % FRAME_SKIP_OCR == 0:\n",
    "        H,W = frame.shape[:2]\n",
    "        roi = frame[\n",
    "            int(H*ROI_Y1_FRAC):int(H*ROI_Y2_FRAC),\n",
    "            int(W*ROI_X1_FRAC):int(W*ROI_X2_FRAC)\n",
    "        ]\n",
    "        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        if is_text_like(gray_roi):\n",
    "            bin_img = preprocess_for_tesseract(roi)\n",
    "            text, conf = tesseract_ocr(bin_img)\n",
    "            if conf >= TESS_CONF_THRESH:\n",
    "                ocr_buffer.append(text)\n",
    "            else:\n",
    "                resized = cv2.resize(gray_roi,(128,32))\n",
    "                inp = (resized/255.0).astype(np.float32)[None,None]\n",
    "                logits = ocr_sess.run(None,{ocr_in:inp})[0]\n",
    "                ocr_buffer.append(decode_ctc(logits))\n",
    "            if len(ocr_buffer)==TEMPORAL_WINDOW and len(set(ocr_buffer))==1:\n",
    "                wagon_texts[wagon_index].append(ocr_buffer[0])\n",
    "                print(f\"[OCR] Wagon #{wagon_index}: {ocr_buffer[0]}\")\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# =====================================================\n",
    "# RESULTS\n",
    "# =====================================================\n",
    "print(\"\\n==============================\")\n",
    "print(f\"‚úÖ TOTAL WAGONS: {wagon_index}\")\n",
    "print(\"==============================\")\n",
    "for i in range(1, wagon_index+1):\n",
    "    texts = wagon_texts[i]\n",
    "    if texts:\n",
    "        print(f\"Wagon #{i}: {max(set(texts), key=texts.count)}\")\n",
    "    else:\n",
    "        print(f\"Wagon #{i}: <NO TEXT>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "VIDEO_PATH = Path(\"raw_videos/high_speed_axis_55kmph_night.mp4\")\n",
    "print(\"Exists:\", VIDEO_PATH.exists())\n",
    "print(\"Absolute path:\", VIDEO_PATH.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3619f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, deque\n",
    "from pathlib import Path\n",
    "import onnxruntime as ort\n",
    "import os\n",
    "\n",
    "# =====================================================\n",
    "# PATHS\n",
    "# =====================================================\n",
    "VIDEO_PATH = Path(\"../data/raw_videos/high_speed_axis_55kmph_night.mp4\")\n",
    "\n",
    "LOWLIGHT_ONNX = Path(\"../onnx_models/lowlight.onnx\")\n",
    "DEBLUR_ONNX   = Path(\"../onnx_models/deblur.onnx\")\n",
    "OCR_ONNX      = Path(\"../onnx_models/ocr.onnx\")\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"Video:\", VIDEO_PATH.resolve())\n",
    "assert VIDEO_PATH.exists(), \"‚ùå Video not found\"\n",
    "\n",
    "# =====================================================\n",
    "# GAP DETECTION\n",
    "# =====================================================\n",
    "MIN_GAP_DROP = 0.08\n",
    "COOLDOWN_FRAMES = 10\n",
    "\n",
    "# =====================================================\n",
    "# STRICT ENHANCEMENT\n",
    "# =====================================================\n",
    "LOWLIGHT_MEAN_THRESH = 40\n",
    "LOWLIGHT_STD_THRESH  = 25\n",
    "BLUR_LAPLACIAN_THRESH = 35.0\n",
    "\n",
    "# =====================================================\n",
    "# OCR (CRNN ONLY)\n",
    "# =====================================================\n",
    "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "FRAME_SKIP_OCR = 3\n",
    "TEMPORAL_WINDOW = 5\n",
    "\n",
    "EDGE_DENSITY_THRESH = 0.02\n",
    "CRNN_CONF_THRESH = 0.75   # VERY IMPORTANT\n",
    "\n",
    "ROI_X1_FRAC = 0.25\n",
    "ROI_X2_FRAC = 0.75\n",
    "ROI_Y1_FRAC = 0.45\n",
    "ROI_Y2_FRAC = 0.65\n",
    "\n",
    "# =====================================================\n",
    "# PATCH DEBLUR PARAMS\n",
    "# =====================================================\n",
    "TILE_SIZE = 256\n",
    "OVERLAP = 32\n",
    "STEP = TILE_SIZE - OVERLAP\n",
    "\n",
    "# =====================================================\n",
    "# LOAD MODELS\n",
    "# =====================================================\n",
    "providers = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "\n",
    "low_sess = ort.InferenceSession(str(LOWLIGHT_ONNX), providers=providers)\n",
    "deb_sess = ort.InferenceSession(str(DEBLUR_ONNX), providers=providers)\n",
    "ocr_sess = ort.InferenceSession(str(OCR_ONNX), providers=providers)\n",
    "\n",
    "low_in = low_sess.get_inputs()[0].name\n",
    "deb_in = deb_sess.get_inputs()[0].name\n",
    "ocr_in = ocr_sess.get_inputs()[0].name\n",
    "\n",
    "# =====================================================\n",
    "# HELPERS\n",
    "# =====================================================\n",
    "def softmax(x, axis=-1):\n",
    "    x = x - np.max(x, axis=axis, keepdims=True)\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e, axis=axis, keepdims=True)\n",
    "\n",
    "def decode_ctc_with_conf(logits):\n",
    "    probs = softmax(logits, axis=-1)\n",
    "    preds = probs.argmax(axis=-1)[0]\n",
    "\n",
    "    prev = -1\n",
    "    text = \"\"\n",
    "    confs = []\n",
    "\n",
    "    for t, p in enumerate(preds):\n",
    "        if p != prev and p > 0 and p <= len(ALPHABET):\n",
    "            text += ALPHABET[p - 1]\n",
    "            confs.append(probs[0, t, p])\n",
    "        prev = p\n",
    "\n",
    "    mean_conf = float(np.mean(confs)) if confs else 0.0\n",
    "    return text, mean_conf\n",
    "\n",
    "def is_text_like(gray):\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    return (edges.mean() / 255.0) > EDGE_DENSITY_THRESH\n",
    "\n",
    "def is_low_light(gray):\n",
    "    return gray.mean() < LOWLIGHT_MEAN_THRESH and gray.std() < LOWLIGHT_STD_THRESH\n",
    "\n",
    "def is_blurry(gray):\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var() < BLUR_LAPLACIAN_THRESH\n",
    "\n",
    "def apply_zero_dce(img, curves):\n",
    "    out = img\n",
    "    for i in range(8):\n",
    "        r = curves[:, i*3:(i+1)*3]\n",
    "        out = out + r * (out*out - out)\n",
    "    return np.clip(out, 0, 1)\n",
    "\n",
    "def patch_deblur(frame):\n",
    "    h, w, _ = frame.shape\n",
    "    tiles, coords = [], []\n",
    "\n",
    "    for y in range(0, h - TILE_SIZE + 1, STEP):\n",
    "        for x in range(0, w - TILE_SIZE + 1, STEP):\n",
    "            tiles.append(frame[y:y+TILE_SIZE, x:x+TILE_SIZE])\n",
    "            coords.append((y, x))\n",
    "\n",
    "    if not tiles:\n",
    "        return frame\n",
    "\n",
    "    batch = np.stack([\n",
    "        t.astype(np.float32).transpose(2,0,1) / 255.0\n",
    "        for t in tiles\n",
    "    ])\n",
    "\n",
    "    out = deb_sess.run(None, {deb_in: batch})[0].transpose(0,2,3,1)\n",
    "\n",
    "    acc = np.zeros((h,w,3), np.float32)\n",
    "    weight = np.zeros((h,w,1), np.float32)\n",
    "\n",
    "    for (y,x), tile in zip(coords, out):\n",
    "        acc[y:y+TILE_SIZE, x:x+TILE_SIZE] += tile\n",
    "        weight[y:y+TILE_SIZE, x:x+TILE_SIZE] += 1\n",
    "\n",
    "    return (np.clip(acc / np.maximum(weight,1e-6),0,1)*255).astype(np.uint8)\n",
    "\n",
    "# =====================================================\n",
    "# MAIN LOOP\n",
    "# =====================================================\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "assert cap.isOpened(), \"‚ùå Cannot open video\"\n",
    "\n",
    "prev_profile = None\n",
    "cooldown = 0\n",
    "wagon_index = 1\n",
    "\n",
    "ocr_buffer = deque(maxlen=TEMPORAL_WINDOW)\n",
    "wagon_texts = defaultdict(list)\n",
    "\n",
    "print(\"üöÜ START ‚Üí Wagon #1\")\n",
    "\n",
    "pbar = tqdm(desc=\"Processing video\", unit=\"frame\")\n",
    "frame_id = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_id += 1\n",
    "    pbar.update(1)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    profile = gray.mean(axis=0)\n",
    "\n",
    "    # ---------- GAP DETECTION ----------\n",
    "    if prev_profile is not None:\n",
    "        diff = np.abs(prev_profile - profile)\n",
    "        drop = diff.mean() / (profile.mean() + 1e-6)\n",
    "        if drop > MIN_GAP_DROP and cooldown == 0:\n",
    "            wagon_index += 1\n",
    "            cooldown = COOLDOWN_FRAMES\n",
    "            print(f\"\\nüîπ GAP ‚Üí Wagon #{wagon_index}\")\n",
    "\n",
    "    prev_profile = profile\n",
    "    cooldown = max(0, cooldown - 1)\n",
    "\n",
    "    # ---------- STRICT VISUAL ENHANCEMENT ----------\n",
    "    vis = frame.copy()\n",
    "    if is_low_light(gray):\n",
    "        rgb = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
    "        inp = (rgb/255.0).transpose(2,0,1)[None]\n",
    "        curves = low_sess.run(None, {low_in: inp})[0]\n",
    "        vis = (apply_zero_dce(inp, curves)[0].transpose(1,2,0)*255).astype(np.uint8)\n",
    "\n",
    "    if is_blurry(gray):\n",
    "        vis = patch_deblur(vis)\n",
    "\n",
    "    # ---------- OCR (CRNN ONLY, RAW FRAME) ----------\n",
    "    if frame_id % FRAME_SKIP_OCR == 0:\n",
    "        H,W = frame.shape[:2]\n",
    "        roi = frame[\n",
    "            int(H*ROI_Y1_FRAC):int(H*ROI_Y2_FRAC),\n",
    "            int(W*ROI_X1_FRAC):int(W*ROI_X2_FRAC)\n",
    "        ]\n",
    "\n",
    "        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if is_text_like(gray_roi):\n",
    "            resized = cv2.resize(gray_roi, (128,32))\n",
    "            inp = (resized/255.0).astype(np.float32)[None,None]\n",
    "\n",
    "            logits = ocr_sess.run(None, {ocr_in: inp})[0]\n",
    "            text, conf = decode_ctc_with_conf(logits)\n",
    "\n",
    "            if conf >= CRNN_CONF_THRESH:\n",
    "                ocr_buffer.append(text)\n",
    "\n",
    "            if len(ocr_buffer) == TEMPORAL_WINDOW and len(set(ocr_buffer)) == 1:\n",
    "                wagon_texts[wagon_index].append(ocr_buffer[0])\n",
    "                print(f\"[OCR] Wagon #{wagon_index}: {ocr_buffer[0]}\")\n",
    "\n",
    "cap.release()\n",
    "pbar.close()\n",
    "\n",
    "# =====================================================\n",
    "# RESULTS\n",
    "# =====================================================\n",
    "print(\"\\n==============================\")\n",
    "print(f\"‚úÖ TOTAL WAGONS: {wagon_index}\")\n",
    "print(\"==============================\")\n",
    "\n",
    "for i in range(1, wagon_index+1):\n",
    "    texts = wagon_texts[i]\n",
    "    if texts:\n",
    "        print(f\"Wagon #{i}: {max(set(texts), key=texts.count)}\")\n",
    "    else:\n",
    "        print(f\"Wagon #{i}: <NO TEXT>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5971640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =====================\n",
    "# CONFIG\n",
    "# =====================\n",
    "VIDEO_PATH = Path(\"../data/raw_videos/high_speed_axis_55kmph_night.mp4\")\n",
    "RESIZE_WIDTH = 960\n",
    "\n",
    "LINE_X_RATIO = 0.5\n",
    "STRIP_WIDTH = 12\n",
    "\n",
    "ROI_Y1_RATIO = 0.55\n",
    "ROI_Y2_RATIO = 0.75\n",
    "\n",
    "# ---- FIXED THRESHOLDS ----\n",
    "DIFF_NORM_THRESHOLD = 0.06     # normalized, night-safe\n",
    "COOLDOWN_FRAMES = 40\n",
    "\n",
    "NO_MOTION_FRAMES = 300         # ~4 seconds at ~75fps\n",
    "\n",
    "# =====================\n",
    "# INIT\n",
    "# =====================\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "assert cap.isOpened(), \"‚ùå Cannot open video\"\n",
    "\n",
    "print(\"üöÜ Wagon Counting Started\")\n",
    "\n",
    "wagon_count = 0\n",
    "cooldown = 0\n",
    "no_motion = 0\n",
    "\n",
    "prev_strip = None\n",
    "motion_active = False   # NEW: edge detection\n",
    "\n",
    "pbar = tqdm(desc=\"Processing video\", unit=\"frame\")\n",
    "\n",
    "# =====================\n",
    "# MAIN LOOP\n",
    "# =====================\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    scale = RESIZE_WIDTH / w\n",
    "    frame = cv2.resize(frame, (RESIZE_WIDTH, int(h * scale)))\n",
    "    H, W = frame.shape[:2]\n",
    "\n",
    "    x = int(W * LINE_X_RATIO)\n",
    "    y1 = int(H * ROI_Y1_RATIO)\n",
    "    y2 = int(H * ROI_Y2_RATIO)\n",
    "\n",
    "    strip = frame[y1:y2, x-STRIP_WIDTH:x+STRIP_WIDTH]\n",
    "    gray = cv2.cvtColor(strip, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if prev_strip is None:\n",
    "        prev_strip = gray\n",
    "        continue\n",
    "\n",
    "    diff = cv2.absdiff(gray, prev_strip)\n",
    "    mean_diff = diff.mean() / (gray.mean() + 1e-6)\n",
    "    prev_strip = gray\n",
    "\n",
    "    # =====================\n",
    "    # COUNTING LOGIC (FIXED)\n",
    "    # =====================\n",
    "    if mean_diff > DIFF_NORM_THRESHOLD:\n",
    "        no_motion = 0\n",
    "\n",
    "        if not motion_active and cooldown == 0:\n",
    "            wagon_count += 1\n",
    "            cooldown = COOLDOWN_FRAMES\n",
    "            motion_active = True\n",
    "            print(f\"üÜï WAGON #{wagon_count} DETECTED\")\n",
    "\n",
    "    else:\n",
    "        motion_active = False\n",
    "        no_motion += 1\n",
    "\n",
    "    if cooldown > 0:\n",
    "        cooldown -= 1\n",
    "\n",
    "    # Stop when train gone (FIXED)\n",
    "    if no_motion > NO_MOTION_FRAMES and wagon_count > 0:\n",
    "        print(\"\\nüö´ Train exited scene. Counting stopped.\")\n",
    "        break\n",
    "\n",
    "    # =====================\n",
    "    # VISUALIZATION\n",
    "    # =====================\n",
    "    cv2.line(frame, (x, 0), (x, H), (0, 0, 255), 2)\n",
    "    cv2.rectangle(frame, (x-STRIP_WIDTH, y1), (x+STRIP_WIDTH, y2), (255, 0, 0), 2)\n",
    "\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        f\"Wagons: {wagon_count}\",\n",
    "        (20, 40),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1,\n",
    "        (255, 255, 255),\n",
    "        2\n",
    "    )\n",
    "\n",
    "    cv2.imshow(\"Robust Wagon Counter\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# =====================\n",
    "# DONE\n",
    "# =====================\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "pbar.close()\n",
    "\n",
    "print(\"\\n===================================\")\n",
    "print(f\"‚úÖ TOTAL WAGONS COUNTED: {wagon_count}\")\n",
    "print(\"===================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec52778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Project root: C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\n",
      "üé• Video: C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\data\\raw_videos\\high_speed_axis_55kmph_night.mp4\n",
      "üî† OCR enabled\n",
      "üöÜ Wagon counting started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  36%|‚ñà‚ñà‚ñà‚ñå      | 1100/3082 [00:10<00:21, 93.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #1 at frame 1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  37%|‚ñà‚ñà‚ñà‚ñã      | 1132/3082 [00:11<00:20, 97.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #2 at frame 1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  38%|‚ñà‚ñà‚ñà‚ñä      | 1163/3082 [00:11<00:19, 98.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #3 at frame 1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1196/3082 [00:11<00:18, 102.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #4 at frame 1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1230/3082 [00:12<00:18, 98.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #5 at frame 1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  41%|‚ñà‚ñà‚ñà‚ñà      | 1251/3082 [00:12<00:19, 94.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #6 at frame 1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1282/3082 [00:12<00:19, 93.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #7 at frame 1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1313/3082 [00:13<00:19, 89.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #8 at frame 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1343/3082 [00:13<00:22, 76.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #9 at frame 1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1367/3082 [00:13<00:25, 68.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #10 at frame 1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1397/3082 [00:14<00:24, 67.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #11 at frame 1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1434/3082 [00:14<00:24, 67.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #12 at frame 1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1458/3082 [00:15<00:23, 69.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #13 at frame 1450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1489/3082 [00:15<00:24, 63.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #14 at frame 1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1527/3082 [00:16<00:22, 70.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #15 at frame 1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1565/3082 [00:16<00:22, 67.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #16 at frame 1552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1594/3082 [00:17<00:21, 67.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #17 at frame 1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1619/3082 [00:17<00:21, 68.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #18 at frame 1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1648/3082 [00:18<00:22, 65.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #19 at frame 1642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1680/3082 [00:18<00:20, 66.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #20 at frame 1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1708/3082 [00:19<00:21, 64.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #21 at frame 1702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1740/3082 [00:19<00:19, 68.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #22 at frame 1732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1773/3082 [00:19<00:19, 68.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #23 at frame 1762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1799/3082 [00:20<00:17, 71.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #24 at frame 1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1832/3082 [00:20<00:16, 73.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #25 at frame 1822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1864/3082 [00:21<00:17, 70.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #26 at frame 1852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1895/3082 [00:21<00:17, 68.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #27 at frame 1882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1919/3082 [00:21<00:16, 69.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #28 at frame 1912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1951/3082 [00:22<00:16, 69.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #29 at frame 1942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1983/3082 [00:22<00:15, 70.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #30 at frame 1972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2014/3082 [00:23<00:15, 68.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #31 at frame 2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2039/3082 [00:23<00:14, 73.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #32 at frame 2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2071/3082 [00:24<00:13, 72.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #33 at frame 2062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2103/3082 [00:24<00:13, 73.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #34 at frame 2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2136/3082 [00:25<00:12, 73.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #35 at frame 2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2161/3082 [00:25<00:13, 70.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #36 at frame 2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2192/3082 [00:25<00:13, 66.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #37 at frame 2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2222/3082 [00:26<00:12, 66.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #38 at frame 2215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2259/3082 [00:26<00:12, 68.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #39 at frame 2245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2284/3082 [00:27<00:11, 68.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #40 at frame 2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2314/3082 [00:27<00:10, 70.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #41 at frame 2305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2345/3082 [00:28<00:10, 69.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #42 at frame 2335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2377/3082 [00:28<00:10, 69.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #43 at frame 2365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2408/3082 [00:28<00:09, 68.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #44 at frame 2395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2431/3082 [00:29<00:09, 70.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #45 at frame 2425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2468/3082 [00:29<00:09, 65.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #46 at frame 2455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2493/3082 [00:30<00:08, 66.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #47 at frame 2487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2527/3082 [00:30<00:07, 71.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #48 at frame 2517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2561/3082 [00:31<00:07, 73.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #49 at frame 2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2594/3082 [00:31<00:06, 73.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #50 at frame 2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2620/3082 [00:31<00:06, 73.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #51 at frame 2610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2652/3082 [00:32<00:06, 71.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #52 at frame 2640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2683/3082 [00:32<00:05, 67.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #53 at frame 2670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2714/3082 [00:33<00:05, 71.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #54 at frame 2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2740/3082 [00:33<00:04, 75.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #55 at frame 2732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2773/3082 [00:34<00:04, 71.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #56 at frame 2762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2798/3082 [00:34<00:03, 71.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #57 at frame 2792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2829/3082 [00:34<00:03, 68.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #58 at frame 2822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2918/3082 [00:36<00:02, 80.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö´ Train exited scene\n",
      "\n",
      "===================================\n",
      "‚úÖ TOTAL WAGONS: 58\n",
      "üìÑ CSV saved to: C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\wagon_results.csv\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "# =====================\n",
    "# PATHS\n",
    "# =====================\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\")\n",
    "VIDEO_PATH = PROJECT_ROOT / \"data\" / \"raw_videos\" / \"high_speed_axis_55kmph_night.mp4\"\n",
    "OCR_ONNX = PROJECT_ROOT / \"onnx_models\" / \"ocr.onnx\"\n",
    "CSV_OUT = PROJECT_ROOT / \"wagon_results.csv\"\n",
    "\n",
    "print(\"üìÇ Project root:\", PROJECT_ROOT)\n",
    "print(\"üé• Video:\", VIDEO_PATH)\n",
    "\n",
    "assert VIDEO_PATH.exists(), \"‚ùå Video not found\"\n",
    "\n",
    "OCR_ENABLED = OCR_ONNX.exists()\n",
    "print(\"üî† OCR enabled\" if OCR_ENABLED else \"‚ö† OCR disabled\")\n",
    "\n",
    "# =====================\n",
    "# CONFIG\n",
    "# =====================\n",
    "RESIZE_WIDTH = 960\n",
    "LINE_X_RATIO = 0.50\n",
    "STRIP_WIDTH = 10\n",
    "\n",
    "ROI_Y1_RATIO = 0.55\n",
    "ROI_Y2_RATIO = 0.75\n",
    "\n",
    "DIFF_THRESHOLD = 18\n",
    "COOLDOWN_FRAMES = 30\n",
    "NO_MOTION_FRAMES = 90\n",
    "\n",
    "SHOW_VIDEO = True\n",
    "OCR_CONF_THRESH = 0.5\n",
    "\n",
    "# =====================\n",
    "# OCR\n",
    "# =====================\n",
    "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "def decode_safe(logits):\n",
    "    probs = logits[0]\n",
    "    seq = probs.argmax(axis=1)\n",
    "    text, confs = \"\", []\n",
    "    prev = -1\n",
    "    for t, c in enumerate(seq):\n",
    "        if c != prev and 0 < c <= len(ALPHABET):\n",
    "            text += ALPHABET[c - 1]\n",
    "            confs.append(probs[t, c])\n",
    "        prev = c\n",
    "    return text, float(np.mean(confs)) if confs else 0.0\n",
    "\n",
    "sess = None\n",
    "ocr_input = None\n",
    "if OCR_ENABLED:\n",
    "    sess = ort.InferenceSession(str(OCR_ONNX), providers=[\"CPUExecutionProvider\"])\n",
    "    ocr_input = sess.get_inputs()[0].name\n",
    "\n",
    "# =====================\n",
    "# VIDEO\n",
    "# =====================\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "assert cap.isOpened(), \"‚ùå Cannot open video\"\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(\"üöÜ Wagon counting started\")\n",
    "\n",
    "wagon_count = 0\n",
    "cooldown = 0\n",
    "no_motion = 0\n",
    "train_seen = False\n",
    "\n",
    "wagon_frames = []\n",
    "wagon_times = []\n",
    "wagon_texts = {}\n",
    "\n",
    "prev_strip = None\n",
    "\n",
    "# =====================\n",
    "# MAIN LOOP\n",
    "# =====================\n",
    "for frame_idx in tqdm(range(total_frames), desc=\"Processing video\"):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    scale = RESIZE_WIDTH / w\n",
    "    frame = cv2.resize(frame, (RESIZE_WIDTH, int(h * scale)))\n",
    "    H, W = frame.shape[:2]\n",
    "\n",
    "    x = int(W * LINE_X_RATIO)\n",
    "    y1 = int(H * ROI_Y1_RATIO)\n",
    "    y2 = int(H * ROI_Y2_RATIO)\n",
    "\n",
    "    strip = frame[y1:y2, x-STRIP_WIDTH:x+STRIP_WIDTH]\n",
    "    gray = cv2.cvtColor(strip, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if prev_strip is None:\n",
    "        prev_strip = gray\n",
    "        continue\n",
    "\n",
    "    diff = cv2.absdiff(gray, prev_strip).mean()\n",
    "    prev_strip = gray\n",
    "\n",
    "    # ===== TRAIN LOGIC =====\n",
    "    if diff > DIFF_THRESHOLD:\n",
    "        train_seen = True\n",
    "        no_motion = 0\n",
    "\n",
    "        if cooldown == 0:\n",
    "            wagon_count += 1\n",
    "            wagon_frames.append(frame_idx)\n",
    "            wagon_times.append(frame_idx / fps)\n",
    "            print(f\"üÜï WAGON #{wagon_count} at frame {frame_idx}\")\n",
    "\n",
    "            # OCR (non-blocking)\n",
    "            if OCR_ENABLED:\n",
    "                roi = frame[int(H*0.35):int(H*0.55), int(W*0.60):int(W*0.95)]\n",
    "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "                roi_gray = cv2.resize(roi_gray, (128, 32))\n",
    "                inp = (roi_gray / 255.0).astype(np.float32)[None, None]\n",
    "                if inp.shape == (1,1,32,128):\n",
    "                    logits = sess.run(None, {ocr_input: inp})[0]\n",
    "                    txt, conf = decode_safe(logits)\n",
    "                    wagon_texts[wagon_count] = txt if conf >= OCR_CONF_THRESH else \"<LOW_CONF>\"\n",
    "                else:\n",
    "                    wagon_texts[wagon_count] = \"<OCR_SHAPE_ERR>\"\n",
    "            else:\n",
    "                wagon_texts[wagon_count] = \"<OCR_DISABLED>\"\n",
    "\n",
    "            cooldown = COOLDOWN_FRAMES\n",
    "\n",
    "    else:\n",
    "        if train_seen:\n",
    "            no_motion += 1\n",
    "\n",
    "    if cooldown > 0:\n",
    "        cooldown -= 1\n",
    "\n",
    "    if train_seen and no_motion > NO_MOTION_FRAMES:\n",
    "        print(\"üö´ Train exited scene\")\n",
    "        break\n",
    "\n",
    "    # ===== VIS =====\n",
    "    if SHOW_VIDEO:\n",
    "        cv2.line(frame, (x,0), (x,H), (0,0,255), 2)\n",
    "        cv2.rectangle(frame, (x-STRIP_WIDTH,y1), (x+STRIP_WIDTH,y2), (255,0,0), 2)\n",
    "        cv2.putText(frame, f\"Wagons: {wagon_count}\", (20,40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        cv2.imshow(\"Wagon Counter\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# =====================\n",
    "# CSV\n",
    "# =====================\n",
    "with open(CSV_OUT, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"wagon_index\", \"frame\", \"timestamp_sec\", \"ocr_text\"])\n",
    "    for i in range(wagon_count):\n",
    "        writer.writerow([\n",
    "            i+1,\n",
    "            wagon_frames[i],\n",
    "            round(wagon_times[i], 3),\n",
    "            wagon_texts.get(i+1, \"\")\n",
    "        ])\n",
    "\n",
    "print(\"\\n===================================\")\n",
    "print(f\"‚úÖ TOTAL WAGONS: {wagon_count}\")\n",
    "print(f\"üìÑ CSV saved to: {CSV_OUT}\")\n",
    "print(\"===================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ba4b23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Project root: C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\n",
      "üé• Video: C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\data\\raw_videos\\high_speed_axis_55kmph_night.mp4\n",
      "üî† OCR model: C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\onnx_models\\ocr.onnx\n",
      "üî† OCR enabled\n",
      "üöÜ Wagon counting started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 1088/3082 [00:11<00:19, 100.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÜ Train confirmed at frame 1089\n",
      "üÜï WAGON #1 at frame 1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñã      | 1119/3082 [00:12<00:29, 66.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #2 at frame 1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 1158/3082 [00:12<00:28, 67.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #3 at frame 1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 1179/3082 [00:13<00:37, 50.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #4 at frame 1188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 1218/3082 [00:14<00:28, 64.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #5 at frame 1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 1248/3082 [00:14<00:32, 56.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #6 at frame 1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1278/3082 [00:15<00:29, 61.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #7 at frame 1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1306/3082 [00:16<00:34, 51.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #8 at frame 1308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1332/3082 [00:16<00:31, 55.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #9 at frame 1340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1362/3082 [00:17<00:31, 54.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #10 at frame 1370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1392/3082 [00:17<00:26, 62.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #11 at frame 1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1427/3082 [00:18<00:29, 57.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #12 at frame 1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1454/3082 [00:19<00:29, 54.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #13 at frame 1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1491/3082 [00:20<00:28, 54.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #14 at frame 1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1519/3082 [00:20<00:34, 44.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #15 at frame 1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1548/3082 [00:21<00:32, 47.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #16 at frame 1552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1576/3082 [00:22<00:34, 43.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #17 at frame 1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1611/3082 [00:23<00:30, 48.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #18 at frame 1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1640/3082 [00:24<00:30, 46.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #19 at frame 1642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1667/3082 [00:25<00:31, 44.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #20 at frame 1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1695/3082 [00:25<00:32, 42.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #21 at frame 1702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1732/3082 [00:26<00:26, 50.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #22 at frame 1732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1761/3082 [00:27<00:30, 42.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #23 at frame 1762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1791/3082 [00:28<00:26, 48.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #24 at frame 1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1821/3082 [00:29<00:27, 45.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #25 at frame 1822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1845/3082 [00:30<00:28, 43.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #26 at frame 1852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1882/3082 [00:31<00:25, 47.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #27 at frame 1882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1912/3082 [00:31<00:23, 48.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #28 at frame 1912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1941/3082 [00:32<00:25, 44.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #29 at frame 1942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1970/3082 [00:33<00:23, 47.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #30 at frame 1972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1999/3082 [00:34<00:24, 44.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #31 at frame 2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2032/3082 [00:35<00:21, 49.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #32 at frame 2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2059/3082 [00:36<00:23, 43.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #33 at frame 2062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2087/3082 [00:36<00:20, 49.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #34 at frame 2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2122/3082 [00:37<00:18, 51.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #35 at frame 2122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2151/3082 [00:38<00:17, 51.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #36 at frame 2157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2181/3082 [00:39<00:19, 46.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #37 at frame 2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2213/3082 [00:39<00:17, 49.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #38 at frame 2217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2241/3082 [00:40<00:18, 45.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #39 at frame 2247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2272/3082 [00:41<00:14, 54.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #40 at frame 2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2302/3082 [00:42<00:15, 50.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #41 at frame 2309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2332/3082 [00:42<00:14, 53.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #42 at frame 2339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2369/3082 [00:43<00:13, 52.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #43 at frame 2370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2399/3082 [00:44<00:12, 54.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #44 at frame 2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2430/3082 [00:44<00:10, 60.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #45 at frame 2430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2460/3082 [00:45<00:11, 53.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #46 at frame 2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2489/3082 [00:46<00:10, 58.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #47 at frame 2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2518/3082 [00:46<00:10, 56.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #48 at frame 2520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2548/3082 [00:47<00:10, 51.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #49 at frame 2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2578/3082 [00:48<00:08, 56.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #50 at frame 2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2606/3082 [00:48<00:09, 49.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #51 at frame 2610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2636/3082 [00:49<00:08, 51.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #52 at frame 2640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2664/3082 [00:50<00:08, 48.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #53 at frame 2670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2699/3082 [00:51<00:07, 51.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #54 at frame 2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2729/3082 [00:51<00:06, 50.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #55 at frame 2730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2753/3082 [00:52<00:07, 44.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #56 at frame 2760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2790/3082 [00:53<00:05, 52.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #57 at frame 2790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2875/3082 [00:55<00:03, 52.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö´ Train exited scene\n",
      "\n",
      "===================================\n",
      "‚úÖ TOTAL WAGONS: 57\n",
      "üìÑ CSV saved to: C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\data\\wagon_results.csv\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FULL WAGON COUNTING + FIXED OCR (SINGLE JUPYTER CELL)\n",
    "# ============================================================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import onnxruntime as ort\n",
    "\n",
    "# ============================================================\n",
    "# PATHS (EDIT ONLY IF NEEDED)\n",
    "# ============================================================\n",
    "VIDEO_PATH = Path(r\"C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\data\\raw_videos\\high_speed_axis_55kmph_night.mp4\")\n",
    "OCR_ONNX  = Path(r\"C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\onnx_models\\ocr.onnx\")\n",
    "\n",
    "print(\"üìÇ Project root:\", VIDEO_PATH.parents[2])\n",
    "print(\"üé• Video:\", VIDEO_PATH)\n",
    "print(\"üî† OCR model:\", OCR_ONNX)\n",
    "\n",
    "if not VIDEO_PATH.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Video not found: {VIDEO_PATH}\")\n",
    "if not OCR_ONNX.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå OCR model not found: {OCR_ONNX}\")\n",
    "\n",
    "# ============================================================\n",
    "# OCR SETUP\n",
    "# ============================================================\n",
    "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "def preprocess_for_ocr(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # CLAHE for night contrast\n",
    "    clahe = cv2.createCLAHE(3.0, (8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "\n",
    "    # Adaptive threshold (CRITICAL)\n",
    "    th = cv2.adaptiveThreshold(\n",
    "        gray, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        31, 15\n",
    "    )\n",
    "\n",
    "    # Morphological cleanup\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return th\n",
    "\n",
    "\n",
    "def safe_decode(logits):\n",
    "    probs = logits[0]\n",
    "    seq = probs.argmax(axis=1)\n",
    "\n",
    "    txt = \"\"\n",
    "    confs = []\n",
    "    prev = -1\n",
    "\n",
    "    for t, c in enumerate(seq):\n",
    "        if c != prev and c > 0 and c-1 < len(ALPHABET):\n",
    "            txt += ALPHABET[c-1]\n",
    "            confs.append(probs[t, c])\n",
    "        prev = c\n",
    "\n",
    "    if not confs:\n",
    "        return \"\", 0.0\n",
    "    return txt, float(np.mean(confs))\n",
    "\n",
    "\n",
    "print(\"üî† OCR enabled\")\n",
    "sess = ort.InferenceSession(str(OCR_ONNX), providers=[\"CPUExecutionProvider\"])\n",
    "ocr_input = sess.get_inputs()[0].name\n",
    "\n",
    "# ============================================================\n",
    "# WAGON COUNTING CONFIG (UNCHANGED LOGIC)\n",
    "# ============================================================\n",
    "RESIZE_WIDTH = 960\n",
    "LINE_X_RATIO = 0.5\n",
    "STRIP_WIDTH = 10\n",
    "\n",
    "ROI_Y1_RATIO = 0.55\n",
    "ROI_Y2_RATIO = 0.75\n",
    "\n",
    "DIFF_THRESHOLD = 18\n",
    "COOLDOWN_FRAMES = 30\n",
    "NO_MOTION_FRAMES = 60\n",
    "\n",
    "# ============================================================\n",
    "# VIDEO INIT\n",
    "# ============================================================\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "assert cap.isOpened(), \"‚ùå Cannot open video\"\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "wagon_count = 0\n",
    "cooldown = 0\n",
    "no_motion = 0\n",
    "prev_strip = None\n",
    "train_started = False\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"üöÜ Wagon counting started\")\n",
    "\n",
    "# ============================================================\n",
    "# MAIN LOOP\n",
    "# ============================================================\n",
    "for frame_idx in tqdm(range(total_frames)):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    scale = RESIZE_WIDTH / w\n",
    "    frame = cv2.resize(frame, (RESIZE_WIDTH, int(h * scale)))\n",
    "    H, W = frame.shape[:2]\n",
    "\n",
    "    x = int(W * LINE_X_RATIO)\n",
    "    y1 = int(H * ROI_Y1_RATIO)\n",
    "    y2 = int(H * ROI_Y2_RATIO)\n",
    "\n",
    "    strip = frame[y1:y2, x-STRIP_WIDTH:x+STRIP_WIDTH]\n",
    "    gray_strip = cv2.cvtColor(strip, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if prev_strip is None:\n",
    "        prev_strip = gray_strip\n",
    "        continue\n",
    "\n",
    "    diff = cv2.absdiff(gray_strip, prev_strip)\n",
    "    mean_diff = diff.mean()\n",
    "    prev_strip = gray_strip\n",
    "\n",
    "    if mean_diff > DIFF_THRESHOLD:\n",
    "        no_motion = 0\n",
    "\n",
    "        if not train_started:\n",
    "            train_started = True\n",
    "            print(f\"üöÜ Train confirmed at frame {frame_idx}\")\n",
    "\n",
    "        if cooldown == 0:\n",
    "            wagon_count += 1\n",
    "            cooldown = COOLDOWN_FRAMES\n",
    "            ts = frame_idx / fps\n",
    "\n",
    "            print(f\"üÜï WAGON #{wagon_count} at frame {frame_idx}\")\n",
    "\n",
    "            # =============================\n",
    "            # FIXED OCR (MULTI-FRAME VOTING)\n",
    "            # =============================\n",
    "            texts = []\n",
    "            for offset in [5, 8, 12]:\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx + offset)\n",
    "                r, f2 = cap.read()\n",
    "                if not r:\n",
    "                    continue\n",
    "\n",
    "                roi = f2[y1:y2, x+40:x+300]\n",
    "                roi = cv2.resize(roi, (128, 32))\n",
    "                th = preprocess_for_ocr(roi)\n",
    "\n",
    "                inp = (th / 255.0).astype(np.float32)[None, None]\n",
    "                logits = sess.run(None, {ocr_input: inp})[0]\n",
    "                txt, conf = safe_decode(logits)\n",
    "\n",
    "                if conf > 0.55 and len(txt) >= 3:\n",
    "                    texts.append((txt, conf))\n",
    "\n",
    "            best_text = max(texts, key=lambda x: x[1])[0] if texts else \"<NO_TEXT>\"\n",
    "\n",
    "            results.append([wagon_count, frame_idx, round(ts,3), best_text])\n",
    "\n",
    "    else:\n",
    "        if train_started:\n",
    "            no_motion += 1\n",
    "\n",
    "    if cooldown > 0:\n",
    "        cooldown -= 1\n",
    "\n",
    "    if train_started and no_motion > NO_MOTION_FRAMES:\n",
    "        print(\"üö´ Train exited scene\")\n",
    "        break\n",
    "\n",
    "    # =============================\n",
    "    # VISUAL DISPLAY\n",
    "    # =============================\n",
    "    cv2.line(frame, (x,0), (x,H), (0,0,255), 2)\n",
    "    cv2.rectangle(frame, (x-STRIP_WIDTH,y1), (x+STRIP_WIDTH,y2), (255,0,0), 2)\n",
    "    cv2.putText(frame, f\"Wagons: {wagon_count}\", (20,40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "    cv2.imshow(\"Wagon Counter + OCR\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# ============================================================\n",
    "# SAVE CSV\n",
    "# ============================================================\n",
    "out_csv = VIDEO_PATH.parents[1] / \"wagon_results.csv\"\n",
    "\n",
    "with open(out_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"wagon_index\", \"frame\", \"timestamp_sec\", \"ocr_text\"])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(\"\\n===================================\")\n",
    "print(f\"‚úÖ TOTAL WAGONS: {len(results)}\")\n",
    "print(f\"üìÑ CSV saved to: {out_csv}\")\n",
    "print(\"===================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82dc073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Project root: c:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\notebooks\n",
      "üé• Video: c:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\notebooks\\data\\raw_videos\\high_speed_axis_55kmph_night.mp4\n",
      "üî† OCR model: c:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\notebooks\\onnx_models\\ocr.onnx\n"
     ]
    },
    {
     "ename": "NoSuchFile",
     "evalue": "[ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from c:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\notebooks\\onnx_models\\ocr.onnx failed:Load model c:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\notebooks\\onnx_models\\ocr.onnx failed. File doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNoSuchFile\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# =====================================================\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# LOAD OCR MODEL\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# =====================================================\u001b[39;00m\n\u001b[32m     23\u001b[39m providers = [\u001b[33m\"\u001b[39m\u001b[33mCUDAExecutionProvider\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mCPUExecutionProvider\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m ocr_sess = \u001b[43mort\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mOCR_ONNX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m ocr_in = ocr_sess.get_inputs()[\u001b[32m0\u001b[39m].name\n\u001b[32m     27\u001b[39m ALPHABET = \u001b[33m\"\u001b[39m\u001b[33m0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\gpuenv\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:485\u001b[39m, in \u001b[36mInferenceSession.__init__\u001b[39m\u001b[34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[39m\n\u001b[32m    482\u001b[39m disabled_optimizers = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mdisabled_optimizers\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_inference_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    487\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_fallback:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\gpuenv\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:573\u001b[39m, in \u001b[36mInferenceSession._create_inference_session\u001b[39m\u001b[34m(self, providers, provider_options, disabled_optimizers)\u001b[39m\n\u001b[32m    570\u001b[39m \u001b[38;5;28mself\u001b[39m._register_ep_custom_ops(session_options, providers, provider_options, available_providers)\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model_path:\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     sess = \u001b[43mC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_config_from_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    575\u001b[39m     sess = C.InferenceSession(session_options, \u001b[38;5;28mself\u001b[39m._model_bytes, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mself\u001b[39m._read_config_from_model)\n",
      "\u001b[31mNoSuchFile\u001b[39m: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from c:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\notebooks\\onnx_models\\ocr.onnx failed:Load model c:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\notebooks\\onnx_models\\ocr.onnx failed. File doesn't exist"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# =====================================================\n",
    "# JUPYTER-SAFE PROJECT ROOT RESOLUTION\n",
    "# =====================================================\n",
    "NOTEBOOK_DIR = Path.cwd()          # .../AIDTM/notebooks\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent # .../AIDTM\n",
    "\n",
    "VIDEO_PATH = PROJECT_ROOT / \"data\" / \"raw_videos\" / \"high_speed_axis_55kmph_night.mp4\"\n",
    "OCR_ONNX   = PROJECT_ROOT / \"onnx_models\" / \"ocr.onnx\"\n",
    "\n",
    "print(\"üìÇ Notebook dir:\", NOTEBOOK_DIR)\n",
    "print(\"üìÇ Project root:\", PROJECT_ROOT)\n",
    "print(\"üé• Video:\", VIDEO_PATH)\n",
    "print(\"üî† OCR model:\", OCR_ONNX)\n",
    "\n",
    "assert VIDEO_PATH.exists(), f\"‚ùå Video not found: {VIDEO_PATH}\"\n",
    "assert OCR_ONNX.exists(), f\"‚ùå OCR model not found: {OCR_ONNX}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "841f6020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Project root: c:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\n",
      "üé• Video: c:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\data\\raw_videos\\high_speed_axis_55kmph_night.mp4\n",
      "üî† OCR model: c:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\onnx_models\\ocr.onnx\n",
      "üöÜ Wagon counting started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  36%|‚ñà‚ñà‚ñà‚ñå      | 1097/3082 [00:13<00:17, 111.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #1 at frame 1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  37%|‚ñà‚ñà‚ñà‚ñã      | 1130/3082 [00:14<00:24, 79.36it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #2 at frame 1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  37%|‚ñà‚ñà‚ñà‚ñã      | 1155/3082 [00:14<00:29, 66.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #3 at frame 1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  39%|‚ñà‚ñà‚ñà‚ñä      | 1192/3082 [00:15<00:27, 69.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #4 at frame 1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1220/3082 [00:15<00:30, 62.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #5 at frame 1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  41%|‚ñà‚ñà‚ñà‚ñà      | 1249/3082 [00:16<00:27, 65.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #6 at frame 1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1279/3082 [00:16<00:26, 67.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #7 at frame 1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1306/3082 [00:17<00:32, 55.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #8 at frame 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1338/3082 [00:17<00:28, 60.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #9 at frame 1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1372/3082 [00:18<00:28, 60.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #10 at frame 1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1401/3082 [00:18<00:26, 64.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #11 at frame 1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1430/3082 [00:19<00:25, 64.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #12 at frame 1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1458/3082 [00:19<00:27, 59.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #13 at frame 1450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1486/3082 [00:20<00:25, 63.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #14 at frame 1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1528/3082 [00:20<00:26, 58.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #15 at frame 1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1561/3082 [00:21<00:25, 59.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #16 at frame 1552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1590/3082 [00:21<00:22, 65.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #17 at frame 1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1619/3082 [00:22<00:22, 66.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #18 at frame 1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1650/3082 [00:22<00:20, 68.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #19 at frame 1642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1680/3082 [00:23<00:20, 67.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #20 at frame 1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1710/3082 [00:23<00:20, 65.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #21 at frame 1702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1746/3082 [00:24<00:19, 68.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #22 at frame 1732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1774/3082 [00:24<00:20, 65.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #23 at frame 1762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1803/3082 [00:25<00:19, 64.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #24 at frame 1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1832/3082 [00:25<00:19, 64.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #25 at frame 1822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1860/3082 [00:25<00:19, 63.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #26 at frame 1852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1896/3082 [00:26<00:17, 67.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #27 at frame 1882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1925/3082 [00:26<00:17, 65.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #28 at frame 1912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1953/3082 [00:27<00:18, 61.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #29 at frame 1942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1981/3082 [00:27<00:17, 63.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #30 at frame 1972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2010/3082 [00:28<00:16, 64.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #31 at frame 2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2038/3082 [00:28<00:16, 63.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #32 at frame 2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2069/3082 [00:29<00:14, 69.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #33 at frame 2062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2104/3082 [00:29<00:14, 65.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #34 at frame 2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2133/3082 [00:30<00:14, 66.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #35 at frame 2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2162/3082 [00:30<00:14, 64.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #36 at frame 2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2198/3082 [00:31<00:13, 65.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #37 at frame 2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2226/3082 [00:31<00:13, 62.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #38 at frame 2215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2255/3082 [00:32<00:12, 65.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #39 at frame 2245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2284/3082 [00:32<00:12, 65.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #40 at frame 2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2313/3082 [00:32<00:11, 69.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #41 at frame 2305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2343/3082 [00:33<00:11, 66.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #42 at frame 2335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2379/3082 [00:33<00:10, 67.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #43 at frame 2365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2408/3082 [00:34<00:10, 66.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #44 at frame 2395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2437/3082 [00:34<00:10, 64.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #45 at frame 2425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2466/3082 [00:35<00:09, 64.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #46 at frame 2455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2494/3082 [00:35<00:09, 61.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #47 at frame 2487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2529/3082 [00:36<00:08, 61.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #48 at frame 2517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2558/3082 [00:36<00:08, 65.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #49 at frame 2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2587/3082 [00:37<00:07, 65.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #50 at frame 2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2622/3082 [00:37<00:07, 62.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #51 at frame 2610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2650/3082 [00:38<00:06, 62.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #52 at frame 2640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2678/3082 [00:38<00:06, 63.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #53 at frame 2670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2707/3082 [00:39<00:05, 63.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #54 at frame 2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2742/3082 [00:39<00:05, 64.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #55 at frame 2732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2771/3082 [00:40<00:05, 61.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #56 at frame 2762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2801/3082 [00:40<00:04, 66.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #57 at frame 2792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2830/3082 [00:40<00:03, 66.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï WAGON #58 at frame 2822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2888/3082 [00:41<00:02, 69.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö´ Train exited scene\n",
      "\n",
      "===================================\n",
      "‚úÖ TOTAL WAGONS: 58\n",
      "üìÑ CSV saved to: c:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\wagon_results.csv\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# FULL STABLE WAGON COUNTING + FIXED OCR (ONE CELL)\n",
    "# JUPYTER SAFE | NO TESSERACT | OCR ONNX\n",
    "# =====================================================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import onnxruntime as ort\n",
    "\n",
    "# =====================================================\n",
    "# PATHS (JUPYTER SAFE)\n",
    "# =====================================================\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "VIDEO_PATH = PROJECT_ROOT / \"data\" / \"raw_videos\" / \"high_speed_axis_55kmph_night.mp4\"\n",
    "OCR_ONNX   = PROJECT_ROOT / \"onnx_models\" / \"ocr.onnx\"\n",
    "\n",
    "print(\"üìÇ Project root:\", PROJECT_ROOT)\n",
    "print(\"üé• Video:\", VIDEO_PATH)\n",
    "print(\"üî† OCR model:\", OCR_ONNX)\n",
    "\n",
    "assert VIDEO_PATH.exists(), \"‚ùå Video not found\"\n",
    "assert OCR_ONNX.exists(), \"‚ùå OCR ONNX not found\"\n",
    "\n",
    "# =====================================================\n",
    "# LOAD OCR MODEL\n",
    "# =====================================================\n",
    "providers = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    "ocr_sess = ort.InferenceSession(str(OCR_ONNX), providers=providers)\n",
    "ocr_in = ocr_sess.get_inputs()[0].name\n",
    "\n",
    "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "# =====================================================\n",
    "# OCR HELPERS (ROBUST)\n",
    "# =====================================================\n",
    "def softmax(x):\n",
    "    x = x - x.max(axis=-1, keepdims=True)\n",
    "    e = np.exp(x)\n",
    "    return e / e.sum(axis=-1, keepdims=True)\n",
    "\n",
    "def decode_ctc(logits):\n",
    "    probs = softmax(logits)[0]\n",
    "    seq = probs.argmax(axis=-1)\n",
    "    prev = -1\n",
    "    txt, conf = \"\", []\n",
    "    for t, c in enumerate(seq):\n",
    "        if c != prev and c > 0 and c <= len(ALPHABET):\n",
    "            txt += ALPHABET[c-1]\n",
    "            conf.append(probs[t, c])\n",
    "        prev = c\n",
    "    return txt, float(np.mean(conf)) if conf else 0.0\n",
    "\n",
    "def preprocess_big_text(roi):\n",
    "    \"\"\"\n",
    "    Designed specifically for BLUE wagon + WHITE text\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # suppress blue background\n",
    "    mask = cv2.inRange(hsv, (90, 50, 50), (140, 255, 255))\n",
    "    roi[mask > 0] = (0, 0, 0)\n",
    "\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    bin_img = cv2.adaptiveThreshold(\n",
    "        gray, 255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        31, 5\n",
    "    )\n",
    "\n",
    "    return bin_img\n",
    "\n",
    "def ocr_from_roi(roi):\n",
    "    roi = cv2.resize(roi, (128, 32))\n",
    "    roi = preprocess_big_text(roi)\n",
    "    inp = (roi / 255.0).astype(np.float32)[None, None]\n",
    "    logits = ocr_sess.run(None, {ocr_in: inp})[0]\n",
    "    return decode_ctc(logits)\n",
    "\n",
    "# =====================================================\n",
    "# WAGON COUNTING CONFIG (UNCHANGED LOGIC)\n",
    "# =====================================================\n",
    "RESIZE_WIDTH = 960\n",
    "LINE_X_RATIO = 0.5\n",
    "STRIP_WIDTH = 10\n",
    "ROI_Y1_RATIO = 0.55\n",
    "ROI_Y2_RATIO = 0.75\n",
    "DIFF_THRESHOLD = 18\n",
    "COOLDOWN_FRAMES = 30\n",
    "NO_MOTION_FRAMES = 60\n",
    "\n",
    "# =====================================================\n",
    "# MAIN\n",
    "# =====================================================\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "wagon_index = 0\n",
    "cooldown = 0\n",
    "no_motion = 0\n",
    "prev_strip = None\n",
    "\n",
    "wagon_frames = defaultdict(list)\n",
    "results = []\n",
    "\n",
    "print(\"üöÜ Wagon counting started\")\n",
    "\n",
    "for frame_id in tqdm(range(total_frames), desc=\"Processing video\"):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    scale = RESIZE_WIDTH / w\n",
    "    frame = cv2.resize(frame, (RESIZE_WIDTH, int(h * scale)))\n",
    "    H, W = frame.shape[:2]\n",
    "\n",
    "    x = int(W * LINE_X_RATIO)\n",
    "    y1 = int(H * ROI_Y1_RATIO)\n",
    "    y2 = int(H * ROI_Y2_RATIO)\n",
    "\n",
    "    strip = frame[y1:y2, x-STRIP_WIDTH:x+STRIP_WIDTH]\n",
    "    gray = cv2.cvtColor(strip, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if prev_strip is None:\n",
    "        prev_strip = gray\n",
    "        continue\n",
    "\n",
    "    diff = cv2.absdiff(gray, prev_strip).mean()\n",
    "    prev_strip = gray\n",
    "\n",
    "    if diff > DIFF_THRESHOLD:\n",
    "        no_motion = 0\n",
    "        if cooldown == 0:\n",
    "            wagon_index += 1\n",
    "            cooldown = COOLDOWN_FRAMES\n",
    "            print(f\"üÜï WAGON #{wagon_index} at frame {frame_id}\")\n",
    "    else:\n",
    "        no_motion += 1\n",
    "\n",
    "    if cooldown > 0:\n",
    "        cooldown -= 1\n",
    "\n",
    "    if no_motion > NO_MOTION_FRAMES and wagon_index > 0:\n",
    "        print(\"üö´ Train exited scene\")\n",
    "        break\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # OCR COLLECTION (MULTI-FRAME PER WAGON)\n",
    "    # -------------------------------------------------\n",
    "    if wagon_index > 0:\n",
    "        roi = frame[int(H*0.45):int(H*0.7), int(W*0.2):int(W*0.8)]\n",
    "        txt, conf = ocr_from_roi(roi)\n",
    "        if conf > 0.3 and len(txt) >= 3:\n",
    "            wagon_frames[wagon_index].append(txt)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # DISPLAY\n",
    "    # -------------------------------------------------\n",
    "    cv2.line(frame, (x, 0), (x, H), (0,0,255), 2)\n",
    "    cv2.putText(frame, f\"Wagons: {wagon_index}\", (20,40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv2.imshow(\"Wagon Counter + OCR\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# =====================================================\n",
    "# FINAL AGGREGATION + CSV\n",
    "# =====================================================\n",
    "csv_path = PROJECT_ROOT / \"wagon_results.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"wagon_index\", \"ocr_text\"])\n",
    "\n",
    "    for idx in range(1, wagon_index+1):\n",
    "        texts = wagon_frames[idx]\n",
    "        if texts:\n",
    "            text = Counter(texts).most_common(1)[0][0]\n",
    "        else:\n",
    "            text = \"<NO_TEXT>\"\n",
    "        writer.writerow([idx, text])\n",
    "\n",
    "print(\"\\n===================================\")\n",
    "print(f\"‚úÖ TOTAL WAGONS: {wagon_index}\")\n",
    "print(f\"üìÑ CSV saved to: {csv_path}\")\n",
    "print(\"===================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c6fdc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easyocr\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from easyocr) (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.5 in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from easyocr) (0.22.1+cu118)\n",
      "Collecting opencv-python-headless (from easyocr)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from easyocr) (1.16.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from easyocr) (2.1.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from easyocr) (11.0.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from easyocr) (0.25.2)\n",
      "Collecting python-bidi (from easyocr)\n",
      "  Downloading python_bidi-0.6.7-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from easyocr) (6.0.3)\n",
      "Collecting Shapely (from easyocr)\n",
      "  Downloading shapely-2.1.2-cp313-cp313-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting pyclipper (from easyocr)\n",
      "  Downloading pyclipper-1.4.0-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting ninja (from easyocr)\n",
      "  Downloading ninja-1.13.0-py3-none-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from torch->easyocr) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from torch->easyocr) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from torch->easyocr) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from torch->easyocr) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from torch->easyocr) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from torch->easyocr) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from torch->easyocr) (70.2.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from scikit-image->easyocr) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from scikit-image->easyocr) (2025.9.20)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from scikit-image->easyocr) (25.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from sympy>=1.13.3->torch->easyocr) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\manas mehta\\desktop\\projects\\gpuenv\\lib\\site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
      "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.9 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.8/2.9 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.3/2.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.8/2.9 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.4/2.9 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading ninja-1.13.0-py3-none-win_amd64.whl (309 kB)\n",
      "Downloading opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl (38.9 MB)\n",
      "   ---------------------------------------- 0.0/38.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/38.9 MB 3.8 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.6/38.9 MB 3.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 2.1/38.9 MB 3.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.9/38.9 MB 3.6 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 3.7/38.9 MB 3.5 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 4.7/38.9 MB 3.8 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.8/38.9 MB 4.0 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 6.3/38.9 MB 4.0 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 7.1/38.9 MB 3.8 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 7.6/38.9 MB 3.8 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.1/38.9 MB 3.6 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 9.2/38.9 MB 3.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 10.5/38.9 MB 3.9 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 11.5/38.9 MB 4.0 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 12.6/38.9 MB 4.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 13.9/38.9 MB 4.2 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 14.9/38.9 MB 4.3 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 15.7/38.9 MB 4.3 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 16.5/38.9 MB 4.3 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 17.6/38.9 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 18.6/38.9 MB 4.3 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 19.7/38.9 MB 4.3 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 20.4/38.9 MB 4.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 21.5/38.9 MB 4.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 22.8/38.9 MB 4.4 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 23.9/38.9 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 25.2/38.9 MB 4.5 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 26.5/38.9 MB 4.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 27.8/38.9 MB 4.6 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 28.8/38.9 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 30.1/38.9 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.2/38.9 MB 4.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.5/38.9 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.8/38.9 MB 4.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.9/38.9 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.9/38.9 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 37.0/38.9 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.7/38.9 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.9 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.9/38.9 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading pyclipper-1.4.0-cp313-cp313-win_amd64.whl (104 kB)\n",
      "Downloading python_bidi-0.6.7-cp313-cp313-win_amd64.whl (159 kB)\n",
      "Downloading shapely-2.1.2-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.0/1.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.9 MB/s eta 0:00:00\n",
      "Installing collected packages: python-bidi, Shapely, pyclipper, opencv-python-headless, ninja, easyocr\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\Users\\\\Manas Mehta\\\\Desktop\\\\PROJECTS\\\\gpuenv\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install easyocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8cf11cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'easyocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measyocr\u001b[39;00m\n\u001b[32m      2\u001b[39m reader = easyocr.Reader([\u001b[33m'\u001b[39m\u001b[33men\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mhi\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m result = reader.readtext(roi)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'easyocr'"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "reader = easyocr.Reader(['en','hi'])\n",
    "result = reader.readtext(roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c8ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
