{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f906b907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"[INFO] Device:\", DEVICE)\n",
    "\n",
    "# =====================\n",
    "# PATHS\n",
    "# =====================\n",
    "DATA_ROOT = Path(\"../data/datasets/ICDAR2015/Word recognition train set\")\n",
    "GT_FILE = DATA_ROOT / \"gt.txt\"\n",
    "MODEL_SAVE = Path(\"../outputs/models/ocr\")\n",
    "MODEL_SAVE.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "988d57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "NUM_CLASSES = len(ALPHABET) + 1  # +1 for CTC blank\n",
    "\n",
    "char2idx = {c: i for i, c in enumerate(ALPHABET)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c68d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICDARWordDataset(Dataset):\n",
    "    def __init__(self, root, gt_file):\n",
    "        self.root = root\n",
    "        self.samples = []\n",
    "\n",
    "        with open(gt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                name, text = line.strip().split(\",\", 1)\n",
    "                self.samples.append((name, text))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, text = self.samples[idx]\n",
    "        img_path = self.root / img_name\n",
    "\n",
    "        img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (128, 32))\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "        img = torch.from_numpy(img).unsqueeze(0)\n",
    "\n",
    "        label = torch.tensor([char2idx[c] for c in text], dtype=torch.long)\n",
    "\n",
    "        return img, label, len(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "574533b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs, labels, lengths = zip(*batch)\n",
    "\n",
    "    imgs = torch.stack(imgs)\n",
    "    labels = torch.cat(labels)\n",
    "    lengths = torch.tensor(lengths)\n",
    "\n",
    "    return imgs, labels, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ICDARWordDataset(DATA_ROOT, GT_FILE)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "model = CRNN().to(DEVICE)\n",
    "criterion = nn.CTCLoss(blank=NUM_CLASSES-1, zero_infinity=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd19c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/140 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 30\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for imgs, labels, label_lens in tqdm(loader, desc=f\"Epoch {epoch}\"):\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        label_lens = label_lens.to(DEVICE)\n",
    "\n",
    "        preds = model(imgs)\n",
    "        T = preds.size(1)\n",
    "        pred_lens = torch.full(\n",
    "            size=(imgs.size(0),),\n",
    "            fill_value=T,\n",
    "            dtype=torch.long\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        loss = criterion(\n",
    "            preds.permute(1,0,2),\n",
    "            labels,\n",
    "            pred_lens,\n",
    "            label_lens\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"[Epoch {epoch}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"loss\": avg_loss\n",
    "        },\n",
    "        MODEL_SAVE / \"ocr_latest.pth\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aae09a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
