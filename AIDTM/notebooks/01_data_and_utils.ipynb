{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "927336d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Standard library\n",
    "# ===============================\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict, Any\n",
    "\n",
    "# ===============================\n",
    "# Third-party\n",
    "# ===============================\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35aba933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n",
      "[INFO] Directory structure initialized\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# DEVICE\n",
    "# ===============================\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Using device: {DEVICE}\")\n",
    "\n",
    "# ===============================\n",
    "# PROJECT ROOT\n",
    "# ===============================\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "# ===============================\n",
    "# DATA DIRECTORIES\n",
    "# ===============================\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\"\n",
    "DATASETS_DIR = DATA_ROOT / \"datasets\"\n",
    "RAW_VIDEO_DIR = DATA_ROOT / \"raw_videos\"\n",
    "FRAME_DIR = DATA_ROOT / \"extracted_frames\"\n",
    "\n",
    "# ===============================\n",
    "# OUTPUT DIRECTORIES\n",
    "# ===============================\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "MODELS_DIR = OUTPUT_DIR / \"models\"\n",
    "LOGS_DIR = OUTPUT_DIR / \"logs\"\n",
    "PLOTS_DIR = OUTPUT_DIR / \"plots\"\n",
    "\n",
    "# ===============================\n",
    "# CREATE ALL DIRS SAFELY\n",
    "# ===============================\n",
    "ALL_DIRS = [\n",
    "    DATA_ROOT,\n",
    "    DATASETS_DIR,\n",
    "    RAW_VIDEO_DIR,\n",
    "    FRAME_DIR,\n",
    "    OUTPUT_DIR,\n",
    "    MODELS_DIR,\n",
    "    LOGS_DIR,\n",
    "    PLOTS_DIR\n",
    "]\n",
    "\n",
    "for d in ALL_DIRS:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"[INFO] Directory structure initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c8b5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_exists(\n",
    "    dataset_dir: Path,\n",
    "    required_subdirs: Optional[List[str]] = None,\n",
    "    min_files: int = 1\n",
    ") -> bool:\n",
    "    if not dataset_dir.exists():\n",
    "        return False\n",
    "\n",
    "    if required_subdirs:\n",
    "        for sub in required_subdirs:\n",
    "            if not (dataset_dir / sub).exists():\n",
    "                return False\n",
    "\n",
    "    files = [f for f in dataset_dir.rglob(\"*\") if f.is_file()]\n",
    "    return len(files) >= min_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1828a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url: str, output_path: Path):\n",
    "    \"\"\"\n",
    "    Cross-platform downloader (Windows / Linux / Mac).\n",
    "    Downloads only if file does not exist.\n",
    "    \"\"\"\n",
    "    if output_path.exists():\n",
    "        print(f\"[INFO] File already exists: {output_path.name}\")\n",
    "        return\n",
    "\n",
    "    print(f\"[DOWNLOAD] {url}\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, output_path)\n",
    "        print(f\"[INFO] Downloaded to {output_path}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to download {url}\\nReason: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1025c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_archive(archive_path: Path, extract_to: Path):\n",
    "    print(f\"[EXTRACT] {archive_path.name}\")\n",
    "\n",
    "    if archive_path.suffix == \".zip\":\n",
    "        with zipfile.ZipFile(archive_path, \"r\") as z:\n",
    "            z.extractall(extract_to)\n",
    "\n",
    "    elif archive_path.suffixes[-2:] == [\".tar\", \".gz\"]:\n",
    "        with tarfile.open(archive_path, \"r:gz\") as t:\n",
    "            t.extractall(extract_to)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported archive format\")\n",
    "\n",
    "    print(\"[INFO] Extraction complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79160fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❗ GoPro dataset NOT found.\n",
      "ACTION REQUIRED:\n",
      "1. Download from: https://seungjunnah.github.io/Datasets/gopro\n",
      "2. Extract into: C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\data\\datasets\\GoPro\n",
      "Expected structure:\n",
      "GoPro/train/blur, GoPro/train/sharp, GoPro/test/blur, GoPro/test/sharp\n"
     ]
    }
   ],
   "source": [
    "GOPRO_DIR = DATASETS_DIR / \"GoPro\"\n",
    "\n",
    "if dataset_exists(GOPRO_DIR, [\"train\", \"test\"]):\n",
    "    print(\"✅ GoPro dataset ready.\")\n",
    "else:\n",
    "    print(\n",
    "        \"\\n❗ GoPro dataset NOT found.\\n\"\n",
    "        \"ACTION REQUIRED:\\n\"\n",
    "        \"1. Download from: https://seungjunnah.github.io/Datasets/gopro\\n\"\n",
    "        f\"2. Extract into: {GOPRO_DIR}\\n\"\n",
    "        \"Expected structure:\\n\"\n",
    "        \"GoPro/train/blur, GoPro/train/sharp, GoPro/test/blur, GoPro/test/sharp\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9cec59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❗ RealBlur dataset NOT found.\n",
      "Download from: https://cg.postech.ac.kr/research/realblur/\n",
      "Extract into: C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\data\\datasets\\RealBlur\n"
     ]
    }
   ],
   "source": [
    "REALBLUR_DIR = DATASETS_DIR / \"RealBlur\"\n",
    "\n",
    "if dataset_exists(REALBLUR_DIR):\n",
    "    print(\"✅ RealBlur dataset ready.\")\n",
    "else:\n",
    "    print(\n",
    "        \"\\n❗ RealBlur dataset NOT found.\\n\"\n",
    "        \"Download from: https://cg.postech.ac.kr/research/realblur/\\n\"\n",
    "        f\"Extract into: {REALBLUR_DIR}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fc337b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❗ LOL dataset NOT found.\n",
      "\n",
      "ACTION REQUIRED:\n",
      "1. Download the LOL dataset manually from one of these sources:\n",
      "   - https://daooshee.github.io/BMVC2018website/\n",
      "   - https://github.com/daooshee/Low-light-image-enhancement\n",
      "\n",
      "2. Extract it into:\n",
      "   C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\data\\datasets\\LOL\n",
      "\n",
      "Expected structure:\n",
      "LOL/\n",
      " ├── our485/\n",
      " │    ├── low/\n",
      " │    └── high/\n",
      " └── eval15/\n",
      "      ├── low/\n",
      "      └── high/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOL_DIR = DATASETS_DIR / \"LOL\"\n",
    "\n",
    "if dataset_exists(LOL_DIR, [\"our485\", \"eval15\"]):\n",
    "    print(\"✅ LOL dataset ready.\")\n",
    "else:\n",
    "    print(\n",
    "        \"\\n❗ LOL dataset NOT found.\\n\\n\"\n",
    "        \"ACTION REQUIRED:\\n\"\n",
    "        \"1. Download the LOL dataset manually from one of these sources:\\n\"\n",
    "        \"   - https://daooshee.github.io/BMVC2018website/\\n\"\n",
    "        \"   - https://github.com/daooshee/Low-light-image-enhancement\\n\\n\"\n",
    "        \"2. Extract it into:\\n\"\n",
    "        f\"   {LOL_DIR}\\n\\n\"\n",
    "        \"Expected structure:\\n\"\n",
    "        \"LOL/\\n\"\n",
    "        \" ├── our485/\\n\"\n",
    "        \" │    ├── low/\\n\"\n",
    "        \" │    └── high/\\n\"\n",
    "        \" └── eval15/\\n\"\n",
    "        \"      ├── low/\\n\"\n",
    "        \"      └── high/\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "447ad65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❗ ICDAR 2015 NOT found.\n",
      "Register & download from: https://rrc.cvc.uab.es/?ch=4\n",
      "Extract into: C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\data\\datasets\\ICDAR2015\n"
     ]
    }
   ],
   "source": [
    "ICDAR_DIR = DATASETS_DIR / \"ICDAR2015\"\n",
    "\n",
    "if dataset_exists(ICDAR_DIR):\n",
    "    print(\"✅ ICDAR 2015 dataset ready.\")\n",
    "else:\n",
    "    print(\n",
    "        \"\\n❗ ICDAR 2015 NOT found.\\n\"\n",
    "        \"Register & download from: https://rrc.cvc.uab.es/?ch=4\\n\"\n",
    "        f\"Extract into: {ICDAR_DIR}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf51af3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❗ RailSem19 NOT found.\n",
      "Download from: https://www.railsense.org/datasets/railsem19\n",
      "Extract into: C:\\Users\\Manas Mehta\\Desktop\\PROJECTS\\AIDTM\\data\\datasets\\RailSem19\n"
     ]
    }
   ],
   "source": [
    "RAILSEM_DIR = DATASETS_DIR / \"RailSem19\"\n",
    "\n",
    "if dataset_exists(RAILSEM_DIR):\n",
    "    print(\"✅ RailSem19 dataset ready.\")\n",
    "else:\n",
    "    print(\n",
    "        \"\\n❗ RailSem19 NOT found.\\n\"\n",
    "        \"Download from: https://www.railsense.org/datasets/railsem19\\n\"\n",
    "        f\"Extract into: {RAILSEM_DIR}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67f49b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path: Path) -> np.ndarray:\n",
    "    img = cv2.imread(str(path))\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to read image: {path}\")\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def normalize_img(img: np.ndarray) -> np.ndarray:\n",
    "    return img.astype(np.float32) / 255.0\n",
    "\n",
    "\n",
    "def denormalize_img(img: np.ndarray) -> np.ndarray:\n",
    "    return (img * 255.0).clip(0, 255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ece4e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_image(root: Path):\n",
    "    images = list(root.rglob(\"*.jpg\")) + list(root.rglob(\"*.png\"))\n",
    "    if not images:\n",
    "        print(\"[WARN] No images found.\")\n",
    "        return\n",
    "\n",
    "    img_path = np.random.choice(images)\n",
    "    img = read_image(img_path)\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img)\n",
    "    plt.title(img_path.name)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e31ad3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_from_video(\n",
    "    video_path: Path,\n",
    "    output_dir: Path,\n",
    "    frame_interval: int = 1,\n",
    "    max_frames: Optional[int] = None\n",
    "):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    frame_id = 0\n",
    "    saved = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_id % frame_interval == 0:\n",
    "            out_path = output_dir / f\"frame_{frame_id:06d}.jpg\"\n",
    "            cv2.imwrite(str(out_path), frame)\n",
    "            saved += 1\n",
    "\n",
    "            if max_frames and saved >= max_frames:\n",
    "                break\n",
    "\n",
    "        frame_id += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"[INFO] Extracted {saved} frames\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b61e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_epoch_model(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    loss: float,\n",
    "    save_dir: Path,\n",
    "    metrics: Optional[Dict[str, Any]] = None\n",
    "):\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    path = save_dir / f\"epoch_{epoch:03d}.pth\"\n",
    "\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"loss\": loss,\n",
    "        \"metrics\": metrics\n",
    "    }, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98e4a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: Optional[Any],\n",
    "    epoch: int,\n",
    "    best_metric: float,\n",
    "    save_dir: Path\n",
    "):\n",
    "    path = save_dir / \"checkpoint.pth\"\n",
    "\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"scheduler_state\": scheduler.state_dict() if scheduler else None,\n",
    "        \"best_metric\": best_metric\n",
    "    }, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae7c0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    metric: float,\n",
    "    save_dir: Path\n",
    "):\n",
    "    path = save_dir / \"best_model.pth\"\n",
    "\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"best_metric\": metric\n",
    "    }, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6533217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint_if_exists(\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    checkpoint_path: Path\n",
    "):\n",
    "    if not checkpoint_path.exists():\n",
    "        return model, optimizer, scheduler, 0, None\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "\n",
    "    if scheduler and checkpoint[\"scheduler_state\"]:\n",
    "        scheduler.load_state_dict(checkpoint[\"scheduler_state\"])\n",
    "\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "    best_metric = checkpoint[\"best_metric\"]\n",
    "\n",
    "    print(f\"[INFO] Resuming from epoch {start_epoch}\")\n",
    "    return model, optimizer, scheduler, start_epoch, best_metric\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
